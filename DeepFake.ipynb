{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c86566e-b9b5-4b82-a043-7c54b2bab635",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T18:44:27.357356Z",
     "start_time": "2024-09-01T18:43:25.731627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\r\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (10.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (1.24.3)\r\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (3.7.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from matplotlib) (1.0.5)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from matplotlib) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from matplotlib) (4.51.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from matplotlib) (1.4.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from matplotlib) (24.1)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from matplotlib) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from matplotlib) (6.4.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\r\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m54.8/54.8 MB\u001B[0m \u001B[31m933.7 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:02\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: opencv-python\r\n",
      "Successfully installed opencv-python-4.10.0.84\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python pillow numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d7ea9eeca02b75f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:17:07.453392Z",
     "start_time": "2024-09-01T19:17:06.890066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\r\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\r\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\r\n",
      "Installing collected packages: tqdm\r\n",
      "Successfully installed tqdm-4.66.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a9b7e15dc9af8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:31:13.293036Z",
     "start_time": "2024-09-01T19:29:56.868234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By pressing any key to continue you confirm that you have agreed to the FaceForensics terms of use as described at:\n",
      "https://github.com/ondyari/FaceForensics\n",
      "***\n",
      "Press any key to continue, or CTRL-C to exit.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 232\u001B[0m\n\u001B[1;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    231\u001B[0m     args \u001B[38;5;241m=\u001B[39m parse_args()\n\u001B[0;32m--> 232\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[13], line 117\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(args)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m***\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPress any key to continue, or CTRL-C to exit.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 117\u001B[0m _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;66;03m# Extract arguments\u001B[39;00m\n\u001B[1;32m    120\u001B[0m c_datasets \u001B[38;5;241m=\u001B[39m [args\u001B[38;5;241m.\u001B[39mdataset] \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mdataset \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m ALL_DATASETS\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/ipykernel/kernelbase.py:1262\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[0;34m(self, prompt)\u001B[0m\n\u001B[1;32m   1260\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[0;32m-> 1262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1263\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1264\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1265\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1266\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1267\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/ipykernel/kernelbase.py:1305\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[0;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[1;32m   1303\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[1;32m   1304\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1306\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1307\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import urllib\n",
    "import urllib.request\n",
    "import tempfile\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "\n",
    "# URLs and filenames\n",
    "FILELIST_URL = 'misc/filelist.json'\n",
    "DEEPFEAKES_DETECTION_URL = 'misc/deepfake_detection_filenames.json'\n",
    "DEEPFAKES_MODEL_NAMES = ['decoder_A.h5', 'decoder_B.h5', 'encoder.h5']\n",
    "\n",
    "# Parameters\n",
    "DATASETS = {\n",
    "    'original_youtube_videos': 'misc/downloaded_youtube_videos.zip',\n",
    "    'original_youtube_videos_info': 'misc/downloaded_youtube_videos_info.zip',\n",
    "    'original': 'original_sequences/youtube',\n",
    "    'DeepFakeDetection_original': 'original_sequences/actors',\n",
    "    'Deepfakes': 'manipulated_sequences/Deepfakes',\n",
    "    'DeepFakeDetection': 'manipulated_sequences/DeepFakeDetection',\n",
    "    'Face2Face': 'manipulated_sequences/Face2Face',\n",
    "    'FaceShifter': 'manipulated_sequences/FaceShifter',\n",
    "    'FaceSwap': 'manipulated_sequences/FaceSwap',\n",
    "    'NeuralTextures': 'manipulated_sequences/NeuralTextures'\n",
    "}\n",
    "ALL_DATASETS = ['original', 'DeepFakeDetection_original', 'Deepfakes',\n",
    "                'DeepFakeDetection', 'Face2Face', 'FaceShifter', 'FaceSwap',\n",
    "                'NeuralTextures']\n",
    "COMPRESSION = ['raw', 'c23', 'c40']\n",
    "TYPE = ['videos', 'masks', 'models']\n",
    "SERVERS = ['EU', 'EU2', 'CA']\n",
    "\n",
    "def parse_args():\n",
    "    if 'ipykernel' in sys.modules:\n",
    "        # Running in Jupyter, bypass argparse\n",
    "        class Args:\n",
    "            output_path = 'your_default_output_path'  # Set your default value\n",
    "            dataset = 'all'\n",
    "            compression = 'raw'\n",
    "            type = 'videos'\n",
    "            num_videos = None\n",
    "            server = 'EU'\n",
    "            tos_url = 'https://github.com/ondyari/FaceForensics'  # Set the TOS URL\n",
    "\n",
    "        return Args()\n",
    "\n",
    "    else:\n",
    "        # Regular argparse\n",
    "        parser = argparse.ArgumentParser(\n",
    "            description='Downloads FaceForensics v2 public data release.',\n",
    "            formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
    "        )\n",
    "        parser.add_argument('output_path', type=str, help='Output directory.')\n",
    "        parser.add_argument('-d', '--dataset', type=str, default='all',\n",
    "                            choices=list(DATASETS.keys()) + ['all'])\n",
    "        parser.add_argument('-c', '--compression', type=str, default='raw',\n",
    "                            choices=COMPRESSION)\n",
    "        parser.add_argument('-t', '--type', type=str, default='videos',\n",
    "                            choices=TYPE)\n",
    "        parser.add_argument('-n', '--num_videos', type=int, default=None)\n",
    "        parser.add_argument('--server', type=str, default='EU',\n",
    "                            choices=SERVERS)\n",
    "        parser.add_argument('--tos_url', type=str,\n",
    "                            default='https://github.com/ondyari/FaceForensics',\n",
    "                            help='URL to the terms of service.')\n",
    "\n",
    "        args, unknown = parser.parse_known_args()\n",
    "        return args\n",
    "\n",
    "def download_files(filenames, base_url, output_path, report_progress=True):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    if report_progress:\n",
    "        filenames = tqdm(filenames)\n",
    "    for filename in filenames:\n",
    "        download_file(base_url + filename, join(output_path, filename))\n",
    "\n",
    "def reporthook(count, block_size, total_size):\n",
    "    global start_time\n",
    "    if count == 0:\n",
    "        start_time = time.time()\n",
    "        return\n",
    "    duration = time.time() - start_time\n",
    "    progress_size = int(count * block_size)\n",
    "    speed = int(progress_size / (1024 * duration))\n",
    "    percent = int(count * block_size * 100 / total_size)\n",
    "    sys.stdout.write(\"\\rProgress: %d%%, %d MB, %d KB/s, %d seconds passed\" %\n",
    "                     (percent, progress_size / (1024 * 1024), speed, duration))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def download_file(url, out_file, report_progress=False):\n",
    "    out_dir = os.path.dirname(out_file)\n",
    "    if not os.path.isfile(out_file):\n",
    "        fh, out_file_tmp = tempfile.mkstemp(dir=out_dir)\n",
    "        f = os.fdopen(fh, 'w')\n",
    "        f.close()\n",
    "        if report_progress:\n",
    "            urllib.request.urlretrieve(url, out_file_tmp,\n",
    "                                       reporthook=reporthook)\n",
    "        else:\n",
    "            urllib.request.urlretrieve(url, out_file_tmp)\n",
    "        os.rename(out_file_tmp, out_file)\n",
    "    else:\n",
    "        tqdm.write('WARNING: skipping download of existing file ' + out_file)\n",
    "\n",
    "def main(args):\n",
    "    # TOS\n",
    "    print('By pressing any key to continue you confirm that you have agreed ' \\\n",
    "          'to the FaceForensics terms of use as described at:')\n",
    "    print(args.tos_url)\n",
    "    print('***')\n",
    "    print('Press any key to continue, or CTRL-C to exit.')\n",
    "    _ = input('')\n",
    "\n",
    "    # Extract arguments\n",
    "    c_datasets = [args.dataset] if args.dataset != 'all' else ALL_DATASETS\n",
    "    c_type = args.type\n",
    "    c_compression = args.compression\n",
    "    num_videos = args.num_videos\n",
    "    output_path = args.output_path\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Check for special dataset cases\n",
    "    for dataset in c_datasets:\n",
    "        dataset_path = DATASETS[dataset]\n",
    "        # Special cases\n",
    "        if 'original_youtube_videos' in dataset:\n",
    "            # Here we download the original youtube videos zip file\n",
    "            print('Downloading original youtube videos.')\n",
    "            if not 'info' in dataset_path:\n",
    "                print('Please be patient, this may take a while (~40gb)')\n",
    "                suffix = ''\n",
    "            else:\n",
    "                suffix = 'info'\n",
    "            download_file(args.base_url + '/' + dataset_path,\n",
    "                          out_file=join(output_path,\n",
    "                                        'downloaded_videos{}.zip'.format(\n",
    "                                            suffix)),\n",
    "                          report_progress=True)\n",
    "            return\n",
    "\n",
    "        # Else: regular datasets\n",
    "        print('Downloading {} of dataset \"{}\"'.format(\n",
    "            c_type, dataset_path\n",
    "        ))\n",
    "\n",
    "        # Get filelists and video lengths list from server\n",
    "        if 'DeepFakeDetection' in dataset_path or 'actors' in dataset_path:\n",
    "            filepaths = json.loads(urllib.request.urlopen(args.base_url + '/' +\n",
    "                                                          DEEPFEAKES_DETECTION_URL).read().decode(\"utf-8\"))\n",
    "            if 'actors' in dataset_path:\n",
    "                filelist = filepaths['actors']\n",
    "            else:\n",
    "                filelist = filepaths['DeepFakesDetection']\n",
    "        elif 'original' in dataset_path:\n",
    "            # Load filelist from server\n",
    "            file_pairs = json.loads(urllib.request.urlopen(args.base_url + '/' +\n",
    "                                                           FILELIST_URL).read().decode(\"utf-8\"))\n",
    "            filelist = []\n",
    "            for pair in file_pairs:\n",
    "                filelist += pair\n",
    "        else:\n",
    "            # Load filelist from server\n",
    "            file_pairs = json.loads(urllib.request.urlopen(args.base_url + '/' +\n",
    "                                                           FILELIST_URL).read().decode(\"utf-8\"))\n",
    "            # Get filelist\n",
    "            filelist = []\n",
    "            for pair in file_pairs:\n",
    "                filelist.append('_'.join(pair))\n",
    "                if c_type != 'models':\n",
    "                    filelist.append('_'.join(pair[::-1]))\n",
    "        # Maybe limit number of videos for download\n",
    "        if num_videos is not None and num_videos > 0:\n",
    "            print('Downloading the first {} videos'.format(num_videos))\n",
    "            filelist = filelist[:num_videos]\n",
    "\n",
    "        # Server and local paths\n",
    "        dataset_videos_url = args.base_url + '{}/{}/{}/'.format(\n",
    "            dataset_path, c_compression, c_type)\n",
    "        dataset_mask_url = args.base_url + '{}/{}/videos/'.format(\n",
    "            dataset_path, 'masks', c_type)\n",
    "\n",
    "        if c_type == 'videos':\n",
    "            dataset_output_path = join(output_path, dataset_path, c_compression,\n",
    "                                       c_type)\n",
    "            print('Output path: {}'.format(dataset_output_path))\n",
    "            filelist = [filename + '.mp4' for filename in filelist]\n",
    "            download_files(filelist, dataset_videos_url, dataset_output_path)\n",
    "        elif c_type == 'masks':\n",
    "            dataset_output_path = join(output_path, dataset_path, c_type,\n",
    "                                       'videos')\n",
    "            print('Output path: {}'.format(dataset_output_path))\n",
    "            if 'original' in dataset:\n",
    "                if args.dataset != 'all':\n",
    "                    print('Only videos available for original data. Aborting.')\n",
    "                    return\n",
    "                else:\n",
    "                    print('Only videos available for original data. '\n",
    "                          'Skipping original.\\n')\n",
    "                    continue\n",
    "            if 'FaceShifter' in dataset:\n",
    "                print('Masks not available for FaceShifter. Aborting.')\n",
    "                return\n",
    "            filelist = [filename + '.mp4' for filename in filelist]\n",
    "            download_files(filelist, dataset_mask_url, dataset_output_path)\n",
    "\n",
    "        # Else: models for deepfakes\n",
    "        else:\n",
    "            if dataset != 'Deepfakes' and c_type == 'models':\n",
    "                print('Models only available for Deepfakes. Aborting')\n",
    "                return\n",
    "            dataset_output_path = join(output_path, dataset_path, c_type)\n",
    "            print('Output path: {}'.format(dataset_output_path))\n",
    "\n",
    "            # Get Deepfakes models\n",
    "            for folder in tqdm(filelist):\n",
    "                folder_filelist = DEEPFAKES_MODEL_NAMES\n",
    "                dataset_videos_url = args.base_url + \\\n",
    "                                     '{}/models/{}/'.format(\n",
    "                                         dataset_path, folder)\n",
    "                download_files(folder_filelist, dataset_videos_url,\n",
    "                               join(dataset_output_path, folder))\n",
    "\n",
    "    print('Done.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3ba72ad-e737-491e-8fd0-bfb42663a6f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:31:16.836535Z",
     "start_time": "2024-09-01T19:31:16.816983Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             [-d {original_youtube_videos,original_youtube_videos_info,original,DeepFakeDetection_original,Deepfakes,DeepFakeDetection,Face2Face,FaceShifter,FaceSwap,NeuralTextures,all}]\n",
      "                             [-c {raw,c23,c40}] [-t {videos,masks,models}]\n",
      "                             [-n NUM_VIDEOS] [--server {EU,EU2,CA}]\n",
      "                             output_path\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[0;31mSystemExit\u001B[0m\u001B[0;31m:\u001B[0m 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "import os\n",
    "import urllib.request\n",
    "import tempfile\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "\n",
    "# URLs and filenames\n",
    "FILELIST_URL = 'misc/filelist.json'\n",
    "DEEPFAKES_DETECTION_URL = 'misc/deepfake_detection_filenames.json'\n",
    "DEEPFAKES_MODEL_NAMES = ['decoder_A.h5', 'decoder_B.h5', 'encoder.h5']\n",
    "\n",
    "# Parameters\n",
    "DATASETS = {\n",
    "    'original_youtube_videos': 'misc/downloaded_youtube_videos.zip',\n",
    "    'original_youtube_videos_info': 'misc/downloaded_youtube_videos_info.zip',\n",
    "    'original': 'original_sequences/youtube',\n",
    "    'DeepFakeDetection_original': 'original_sequences/actors',\n",
    "    'Deepfakes': 'manipulated_sequences/Deepfakes',\n",
    "    'DeepFakeDetection': 'manipulated_sequences/DeepFakeDetection',\n",
    "    'Face2Face': 'manipulated_sequences/Face2Face',\n",
    "    'FaceShifter': 'manipulated_sequences/FaceShifter',\n",
    "    'FaceSwap': 'manipulated_sequences/FaceSwap',\n",
    "    'NeuralTextures': 'manipulated_sequences/NeuralTextures'\n",
    "}\n",
    "ALL_DATASETS = ['original', 'DeepFakeDetection_original', 'Deepfakes',\n",
    "                'DeepFakeDetection', 'Face2Face', 'FaceShifter', 'FaceSwap',\n",
    "                'NeuralTextures']\n",
    "COMPRESSION = ['raw', 'c23', 'c40']\n",
    "TYPE = ['videos', 'masks', 'models']\n",
    "SERVERS = ['EU', 'EU2', 'CA']\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Downloads FaceForensics v2 public data release.',\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
    "    )\n",
    "    parser.add_argument('output_path', type=str, help='Output directory.')\n",
    "    parser.add_argument('-d', '--dataset', type=str, default='all',\n",
    "                        help='Which dataset to download.',\n",
    "                        choices=list(DATASETS.keys()) + ['all'])\n",
    "    parser.add_argument('-c', '--compression', type=str, default='raw',\n",
    "                        help='Which compression degree.',\n",
    "                        choices=COMPRESSION)\n",
    "    parser.add_argument('-t', '--type', type=str, default='videos',\n",
    "                        help='Which file type.',\n",
    "                        choices=TYPE)\n",
    "    parser.add_argument('-n', '--num_videos', type=int, default=None,\n",
    "                        help='Number of videos to download.')\n",
    "    parser.add_argument('--server', type=str, default='EU',\n",
    "                        help='Server to download from.',\n",
    "                        choices=SERVERS)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # URLs\n",
    "    server = args.server\n",
    "    if server == 'EU':\n",
    "        args.base_url = 'http://canis.vc.in.tum.de:8100/v3/'\n",
    "    elif server == 'EU2':\n",
    "        args.base_url = 'http://kaldir.vc.in.tum.de/faceforensics/v3/'\n",
    "    elif server == 'CA':\n",
    "        args.base_url = 'http://falas.cmpt.sfu.ca:8100/v3/'\n",
    "    else:\n",
    "        raise Exception('Wrong server name. Choices: {}'.format(str(SERVERS)))\n",
    "\n",
    "    args.tos_url = args.base_url.replace('v3/', 'webpage/FaceForensics_TOS.pdf')\n",
    "    args.deepfakes_model_url = args.base_url + 'manipulated_sequences/Deepfakes/models/'\n",
    "\n",
    "    return args\n",
    "\n",
    "def download_files(filenames, base_url, output_path, report_progress=True):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    if report_progress:\n",
    "        filenames = tqdm(filenames)\n",
    "    for filename in filenames:\n",
    "        download_file(base_url + filename, join(output_path, filename))\n",
    "\n",
    "def reporthook(count, block_size, total_size):\n",
    "    global start_time\n",
    "    if count == 0:\n",
    "        start_time = time.time()\n",
    "        return\n",
    "    duration = time.time() - start_time\n",
    "    progress_size = int(count * block_size)\n",
    "    speed = int(progress_size / (1024 * duration))\n",
    "    percent = int(count * block_size * 100 / total_size)\n",
    "    sys.stdout.write(\"\\rProgress: %d%%, %d MB, %d KB/s, %d seconds passed\" %\n",
    "                     (percent, progress_size / (1024 * 1024), speed, duration))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def download_file(url, out_file, report_progress=False):\n",
    "    out_dir = os.path.dirname(out_file)\n",
    "    if not os.path.isfile(out_file):\n",
    "        fh, out_file_tmp = tempfile.mkstemp(dir=out_dir)\n",
    "        f = os.fdopen(fh, 'w')\n",
    "        f.close()\n",
    "        if report_progress:\n",
    "            urllib.request.urlretrieve(url, out_file_tmp, reporthook=reporthook)\n",
    "        else:\n",
    "            urllib.request.urlretrieve(url, out_file_tmp)\n",
    "        os.rename(out_file_tmp, out_file)\n",
    "    else:\n",
    "        tqdm.write('WARNING: skipping download of existing file ' + out_file)\n",
    "\n",
    "def main(args):\n",
    "    # TOS\n",
    "    print('By pressing any key to continue you confirm that you have agreed ' \\\n",
    "          'to the FaceForensics terms of use as described at:')\n",
    "    print(args.tos_url)\n",
    "    print('***')\n",
    "    print('Press any key to continue, or CTRL-C to exit.')\n",
    "    _ = input('')\n",
    "\n",
    "    # Extract arguments\n",
    "    c_datasets = [args.dataset] if args.dataset != 'all' else ALL_DATASETS\n",
    "    c_type = args.type\n",
    "    c_compression = args.compression\n",
    "    num_videos = args.num_videos\n",
    "    output_path = args.output_path\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Check for special dataset cases\n",
    "    for dataset in c_datasets:\n",
    "        dataset_path = DATASETS[dataset]\n",
    "        # Special cases\n",
    "        if 'original_youtube_videos' in dataset:\n",
    "            print('Downloading original youtube videos.')\n",
    "            if not 'info' in dataset_path:\n",
    "                print('Please be patient, this may take a while (~40gb)')\n",
    "                suffix = ''\n",
    "            else:\n",
    "                suffix = 'info'\n",
    "            download_file(args.base_url + dataset_path,\n",
    "                          out_file=join(output_path, 'downloaded_videos{}.zip'.format(suffix)),\n",
    "                          report_progress=True)\n",
    "            return\n",
    "\n",
    "        # Else: regular datasets\n",
    "        print('Downloading {} of dataset \"{}\"'.format(c_type, dataset_path))\n",
    "\n",
    "        # Get filelists and video lengths list from server\n",
    "        if 'DeepFakeDetection' in dataset_path or 'actors' in dataset_path:\n",
    "            filepaths = json.loads(urllib.request.urlopen(args.base_url + DEEPFAKES_DETECTION_URL).read().decode(\"utf-8\"))\n",
    "            if 'actors' in dataset_path:\n",
    "                filelist = filepaths['actors']\n",
    "            else:\n",
    "                filelist = filepaths['DeepFakesDetection']\n",
    "        elif 'original' in dataset_path:\n",
    "            file_pairs = json.loads(urllib.request.urlopen(args.base_url + FILELIST_URL).read().decode(\"utf-8\"))\n",
    "            filelist = []\n",
    "            for pair in file_pairs:\n",
    "                filelist += pair\n",
    "        else:\n",
    "            file_pairs = json.loads(urllib.request.urlopen(args.base_url + FILELIST_URL).read().decode(\"utf-8\"))\n",
    "            filelist = []\n",
    "            for pair in file_pairs:\n",
    "                filelist.append('_'.join(pair))\n",
    "                if c_type != 'models':\n",
    "                    filelist.append('_'.join(pair[::-1]))\n",
    "\n",
    "        # Maybe limit the number of videos for download\n",
    "        if num_videos is not None and num_videos > 0:\n",
    "            print('Downloading the first {} videos'.format(num_videos))\n",
    "            filelist = filelist[:num_videos]\n",
    "\n",
    "        # Server and local paths\n",
    "        dataset_videos_url = args.base_url + '{}/{}/{}/'.format(dataset_path, c_compression, c_type)\n",
    "        dataset_mask_url = args.base_url + '{}/{}/videos/'.format(dataset_path, 'masks')\n",
    "\n",
    "        if c_type == 'videos':\n",
    "            dataset_output_path = join(output_path, dataset_path, c_compression, c_type)\n",
    "            print('Output path: {}'.format(dataset_output_path))\n",
    "            filelist = [filename + '.mp4' for filename in filelist]\n",
    "            download_files(filelist, dataset_videos_url, dataset_output_path)\n",
    "        elif c_type == 'masks':\n",
    "            dataset_output_path = join(output_path, dataset_path, c_type, 'videos')\n",
    "            print('Output path: {}'.format(dataset_output_path))\n",
    "            filelist = [filename + '.png' for filename in filelist]\n",
    "            download_files(filelist, dataset_mask_url, dataset_output_path)\n",
    "        elif c_type == 'models':\n",
    "            if 'Deepfakes' in dataset:\n",
    "                print('Downloading the {} models for Deepfakes'.format(len(DEEPFAKES_MODEL_NAMES)))\n",
    "                dataset_output_path = join(output_path, dataset_path, c_compression, c_type)\n",
    "                print('Output path: {}'.format(dataset_output_path))\n",
    "                download_files(DEEPFAKES_MODEL_NAMES, args.deepfakes_model_url, dataset_output_path)\n",
    "            else:\n",
    "                print('No models to download for dataset {}'.format(dataset))\n",
    "                continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de1e4adc-45d6-43f9-a1ae-eeadc916dc0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:34:54.001696Z",
     "start_time": "2024-09-01T19:34:47.934098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By pressing any key to continue you confirm that you have agreed to the FaceForensics terms of use as described at:\n",
      "https://github.com/ondyari/FaceForensics\n",
      "***\n",
      "Press any key to continue, or CTRL-C to exit.\n",
      "Downloading dataset: all\n",
      "Compression: c23\n",
      "File type: videos\n",
      "Server: EU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "# Simulated command-line arguments\n",
    "sys.argv = [\n",
    "    'download_FaceForensics.py',  # Script name\n",
    "    '/Users/aniketsaxena/Documents/p/python/project/deepFakeDetection/Implementation',  # output_path\n",
    "    '-d', 'all',  # dataset\n",
    "    '-c', 'c23',  # compression\n",
    "    '-t', 'videos',  # type\n",
    "    '--server', 'EU',  # server\n",
    "]\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Download FaceForensics dataset.')\n",
    "    parser.add_argument('output_path', type=str, help='Path to output directory')\n",
    "    parser.add_argument('-d', '--dataset', choices=['original_youtube_videos', 'original_youtube_videos_info', 'original', 'DeepFakeDetection_original', 'Deepfakes', 'DeepFakeDetection', 'Face2Face', 'FaceShifter', 'FaceSwap', 'NeuralTextures', 'all'], default='all', help='Dataset to download')\n",
    "    parser.add_argument('-c', '--compression', choices=['raw', 'c23', 'c40'], default='c23', help='Compression quality')\n",
    "    parser.add_argument('-t', '--type', choices=['videos', 'masks', 'models'], default='videos', help='Type of files to download')\n",
    "    parser.add_argument('-n', '--num_videos', type=int, default=None, help='Number of videos to download')\n",
    "    parser.add_argument('--server', choices=['EU', 'EU2', 'CA'], default='EU', help='Server to use')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def main(args):\n",
    "    # TOS\n",
    "    print('By pressing any key to continue you confirm that you have agreed ' \\\n",
    "          'to the FaceForensics terms of use as described at:')\n",
    "    print('https://github.com/ondyari/FaceForensics')\n",
    "    print('***')\n",
    "    print('Press any key to continue, or CTRL-C to exit.')\n",
    "    input()  # Wait for user input\n",
    "\n",
    "    # Ensure output path exists\n",
    "    if not os.path.exists(args.output_path):\n",
    "        os.makedirs(args.output_path)\n",
    "\n",
    "    # Sample processing based on args (replace this with actual download code)\n",
    "    print(f\"Downloading dataset: {args.dataset}\")\n",
    "    print(f\"Compression: {args.compression}\")\n",
    "    print(f\"File type: {args.type}\")\n",
    "    print(f\"Server: {args.server}\")\n",
    "    if args.num_videos:\n",
    "        print(f\"Number of videos: {args.num_videos}\")\n",
    "\n",
    "    # Your actual downloading logic goes here\n",
    "    # ...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "767801eb55785881",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:37:50.278322Z",
     "start_time": "2024-09-01T19:37:44.327171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By pressing any key to continue you confirm that you have agreed to the FaceForensics terms of use as described at:\n",
      "http://canis.vc.in.tum.de:8100/webpage/FaceForensics_TOS.pdf\n",
      "***\n",
      "Press any key to continue, or CTRL-C to exit.\n",
      "Downloading videos of dataset \"original_sequences/youtube\"\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 61] Connection refused>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mConnectionRefusedError\u001B[0m                    Traceback (most recent call last)",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:1354\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1353\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1354\u001B[0m     \u001B[43mh\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1355\u001B[0m \u001B[43m              \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhas_header\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTransfer-encoding\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1356\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:1256\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1255\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1256\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:1302\u001B[0m, in \u001B[0;36mHTTPConnection._send_request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1301\u001B[0m     body \u001B[38;5;241m=\u001B[39m _encode(body, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbody\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1302\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mendheaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:1251\u001B[0m, in \u001B[0;36mHTTPConnection.endheaders\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1250\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CannotSendHeader()\n\u001B[0;32m-> 1251\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:1011\u001B[0m, in \u001B[0;36mHTTPConnection._send_output\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1010\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer[:]\n\u001B[0;32m-> 1011\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1013\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m message_body \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1014\u001B[0m \n\u001B[1;32m   1015\u001B[0m     \u001B[38;5;66;03m# create a consistent interface to message_body\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:951\u001B[0m, in \u001B[0;36mHTTPConnection.send\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    950\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_open:\n\u001B[0;32m--> 951\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    952\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:922\u001B[0m, in \u001B[0;36mHTTPConnection.connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    921\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 922\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_connection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msource_address\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock\u001B[38;5;241m.\u001B[39msetsockopt(socket\u001B[38;5;241m.\u001B[39mIPPROTO_TCP, socket\u001B[38;5;241m.\u001B[39mTCP_NODELAY, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/socket.py:808\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address)\u001B[0m\n\u001B[1;32m    807\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 808\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[1;32m    809\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    810\u001B[0m     \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/socket.py:796\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address)\u001B[0m\n\u001B[1;32m    795\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n\u001B[0;32m--> 796\u001B[0m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "\u001B[0;31mConnectionRefusedError\u001B[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mURLError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 195\u001B[0m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    194\u001B[0m     args \u001B[38;5;241m=\u001B[39m parse_args()\n\u001B[0;32m--> 195\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[16], line 152\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(args)\u001B[0m\n\u001B[1;32m    150\u001B[0m         filelist \u001B[38;5;241m=\u001B[39m filepaths[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDeepFakesDetection\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moriginal\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m dataset_path:\n\u001B[0;32m--> 152\u001B[0m     file_pairs \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(\u001B[43murllib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_url\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mFILELIST_URL\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mread()\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m    153\u001B[0m     filelist \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    154\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m pair \u001B[38;5;129;01min\u001B[39;00m file_pairs:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:222\u001B[0m, in \u001B[0;36murlopen\u001B[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    221\u001B[0m     opener \u001B[38;5;241m=\u001B[39m _opener\n\u001B[0;32m--> 222\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mopener\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:525\u001B[0m, in \u001B[0;36mOpenerDirector.open\u001B[0;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[1;32m    522\u001B[0m     req \u001B[38;5;241m=\u001B[39m meth(req)\n\u001B[1;32m    524\u001B[0m sys\u001B[38;5;241m.\u001B[39maudit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124murllib.Request\u001B[39m\u001B[38;5;124m'\u001B[39m, req\u001B[38;5;241m.\u001B[39mfull_url, req\u001B[38;5;241m.\u001B[39mdata, req\u001B[38;5;241m.\u001B[39mheaders, req\u001B[38;5;241m.\u001B[39mget_method())\n\u001B[0;32m--> 525\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[38;5;66;03m# post-process response\u001B[39;00m\n\u001B[1;32m    528\u001B[0m meth_name \u001B[38;5;241m=\u001B[39m protocol\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_response\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:542\u001B[0m, in \u001B[0;36mOpenerDirector._open\u001B[0;34m(self, req, data)\u001B[0m\n\u001B[1;32m    539\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[1;32m    541\u001B[0m protocol \u001B[38;5;241m=\u001B[39m req\u001B[38;5;241m.\u001B[39mtype\n\u001B[0;32m--> 542\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_chain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_open\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\n\u001B[1;32m    543\u001B[0m \u001B[43m                          \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_open\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    544\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result:\n\u001B[1;32m    545\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:502\u001B[0m, in \u001B[0;36mOpenerDirector._call_chain\u001B[0;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[1;32m    500\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m handler \u001B[38;5;129;01min\u001B[39;00m handlers:\n\u001B[1;32m    501\u001B[0m     func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(handler, meth_name)\n\u001B[0;32m--> 502\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    503\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    504\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:1383\u001B[0m, in \u001B[0;36mHTTPHandler.http_open\u001B[0;34m(self, req)\u001B[0m\n\u001B[1;32m   1382\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhttp_open\u001B[39m(\u001B[38;5;28mself\u001B[39m, req):\n\u001B[0;32m-> 1383\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhttp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mHTTPConnection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:1357\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1354\u001B[0m         h\u001B[38;5;241m.\u001B[39mrequest(req\u001B[38;5;241m.\u001B[39mget_method(), req\u001B[38;5;241m.\u001B[39mselector, req\u001B[38;5;241m.\u001B[39mdata, headers,\n\u001B[1;32m   1355\u001B[0m                   encode_chunked\u001B[38;5;241m=\u001B[39mreq\u001B[38;5;241m.\u001B[39mhas_header(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTransfer-encoding\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m   1356\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n\u001B[0;32m-> 1357\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m URLError(err)\n\u001B[1;32m   1358\u001B[0m     r \u001B[38;5;241m=\u001B[39m h\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[1;32m   1359\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n",
      "\u001B[0;31mURLError\u001B[0m: <urlopen error [Errno 61] Connection refused>"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import urllib.request\n",
    "import tempfile\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "\n",
    "# URLs and filenames\n",
    "FILELIST_URL = 'misc/filelist.json'\n",
    "DEEPFAKES_DETECTION_URL = 'misc/deepfake_detection_filenames.json'\n",
    "DEEPFAKES_MODEL_NAMES = ['decoder_A.h5', 'decoder_B.h5', 'encoder.h5']\n",
    "\n",
    "# Parameters\n",
    "DATASETS = {\n",
    "    'original_youtube_videos': 'misc/downloaded_youtube_videos.zip',\n",
    "    'original_youtube_videos_info': 'misc/downloaded_youtube_videos_info.zip',\n",
    "    'original': 'original_sequences/youtube',\n",
    "    'DeepFakeDetection_original': 'original_sequences/actors',\n",
    "    'Deepfakes': 'manipulated_sequences/Deepfakes',\n",
    "    'DeepFakeDetection': 'manipulated_sequences/DeepFakeDetection',\n",
    "    'Face2Face': 'manipulated_sequences/Face2Face',\n",
    "    'FaceShifter': 'manipulated_sequences/FaceShifter',\n",
    "    'FaceSwap': 'manipulated_sequences/FaceSwap',\n",
    "    'NeuralTextures': 'manipulated_sequences/NeuralTextures'\n",
    "}\n",
    "ALL_DATASETS = ['original', 'DeepFakeDetection_original', 'Deepfakes',\n",
    "                'DeepFakeDetection', 'Face2Face', 'FaceShifter', 'FaceSwap',\n",
    "                'NeuralTextures']\n",
    "COMPRESSION = ['raw', 'c23', 'c40']\n",
    "TYPE = ['videos', 'masks', 'models']\n",
    "SERVERS = ['EU', 'EU2', 'CA']\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Downloads FaceForensics v2 public data release.',\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
    "    )\n",
    "    parser.add_argument('output_path', type=str, help='Output directory.')\n",
    "    parser.add_argument('-d', '--dataset', type=str, default='all',\n",
    "                        help='Which dataset to download.',\n",
    "                        choices=list(DATASETS.keys()) + ['all'])\n",
    "    parser.add_argument('-c', '--compression', type=str, default='raw',\n",
    "                        help='Which compression degree.',\n",
    "                        choices=COMPRESSION)\n",
    "    parser.add_argument('-t', '--type', type=str, default='videos',\n",
    "                        help='Which file type.',\n",
    "                        choices=TYPE)\n",
    "    parser.add_argument('-n', '--num_videos', type=int, default=None,\n",
    "                        help='Number of videos to download.')\n",
    "    parser.add_argument('--server', type=str, default='EU',\n",
    "                        help='Server to download from.',\n",
    "                        choices=SERVERS)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # URLs\n",
    "    server = args.server\n",
    "    if server == 'EU':\n",
    "        args.base_url = 'http://canis.vc.in.tum.de:8100/v3/'\n",
    "    elif server == 'EU2':\n",
    "        args.base_url = 'http://kaldir.vc.in.tum.de/faceforensics/v3/'\n",
    "    elif server == 'CA':\n",
    "        args.base_url = 'http://falas.cmpt.sfu.ca:8100/v3/'\n",
    "    else:\n",
    "        raise Exception('Wrong server name. Choices: {}'.format(str(SERVERS)))\n",
    "\n",
    "    args.tos_url = args.base_url.replace('v3/', 'webpage/FaceForensics_TOS.pdf')\n",
    "    args.deepfakes_model_url = args.base_url + 'manipulated_sequences/Deepfakes/models/'\n",
    "\n",
    "    return args\n",
    "\n",
    "def download_files(filenames, base_url, output_path, report_progress=True):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    if report_progress:\n",
    "        filenames = tqdm(filenames)\n",
    "    for filename in filenames:\n",
    "        download_file(base_url + filename, join(output_path, filename))\n",
    "\n",
    "def reporthook(count, block_size, total_size):\n",
    "    global start_time\n",
    "    if count == 0:\n",
    "        start_time = time.time()\n",
    "        return\n",
    "    duration = time.time() - start_time\n",
    "    progress_size = int(count * block_size)\n",
    "    speed = int(progress_size / (1024 * duration))\n",
    "    percent = int(count * block_size * 100 / total_size)\n",
    "    sys.stdout.write(\"\\rProgress: %d%%, %d MB, %d KB/s, %d seconds passed\" %\n",
    "                     (percent, progress_size / (1024 * 1024), speed, duration))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def download_file(url, out_file, report_progress=False):\n",
    "    out_dir = os.path.dirname(out_file)\n",
    "    if not os.path.isfile(out_file):\n",
    "        fh, out_file_tmp = tempfile.mkstemp(dir=out_dir)\n",
    "        f = os.fdopen(fh, 'w')\n",
    "        f.close()\n",
    "        if report_progress:\n",
    "            urllib.request.urlretrieve(url, out_file_tmp, reporthook=reporthook)\n",
    "        else:\n",
    "            urllib.request.urlretrieve(url, out_file_tmp)\n",
    "        os.rename(out_file_tmp, out_file)\n",
    "    else:\n",
    "        tqdm.write('WARNING: skipping download of existing file ' + out_file)\n",
    "\n",
    "def main(args):\n",
    "    # TOS\n",
    "    print('By pressing any key to continue you confirm that you have agreed ' \\\n",
    "          'to the FaceForensics terms of use as described at:')\n",
    "    print(args.tos_url)\n",
    "    print('***')\n",
    "    print('Press any key to continue, or CTRL-C to exit.')\n",
    "    _ = input('')\n",
    "\n",
    "    # Extract arguments\n",
    "    c_datasets = [args.dataset] if args.dataset != 'all' else ALL_DATASETS\n",
    "    c_type = args.type\n",
    "    c_compression = args.compression\n",
    "    num_videos = args.num_videos\n",
    "    output_path = args.output_path\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Check for special dataset cases\n",
    "    for dataset in c_datasets:\n",
    "        dataset_path = DATASETS[dataset]\n",
    "        # Special cases\n",
    "        if 'original_youtube_videos' in dataset:\n",
    "            print('Downloading original youtube videos.')\n",
    "            if not 'info' in dataset_path:\n",
    "                print('Please be patient, this may take a while (~40gb)')\n",
    "                suffix = ''\n",
    "            else:\n",
    "                suffix = 'info'\n",
    "            download_file(args.base_url + dataset_path,\n",
    "                          out_file=join(output_path, 'downloaded_videos{}.zip'.format(suffix)),\n",
    "                          report_progress=True)\n",
    "            return\n",
    "\n",
    "        # Else: regular datasets\n",
    "        print('Downloading {} of dataset \"{}\"'.format(c_type, dataset_path))\n",
    "\n",
    "        # Get filelists and video lengths list from server\n",
    "        if 'DeepFakeDetection' in dataset_path or 'actors' in dataset_path:\n",
    "            filepaths = json.loads(urllib.request.urlopen(args.base_url + DEEPFAKES_DETECTION_URL).read().decode(\"utf-8\"))\n",
    "            if 'actors' in dataset_path:\n",
    "                filelist = filepaths['actors']\n",
    "            else:\n",
    "                filelist = filepaths['DeepFakesDetection']\n",
    "        elif 'original' in dataset_path:\n",
    "            file_pairs = json.loads(urllib.request.urlopen(args.base_url + FILELIST_URL).read().decode(\"utf-8\"))\n",
    "            filelist = []\n",
    "            for pair in file_pairs:\n",
    "                filelist += pair\n",
    "        else:\n",
    "            file_pairs = json.loads(urllib.request.urlopen(args.base_url + FILELIST_URL).read().decode(\"utf-8\"))\n",
    "            filelist = []\n",
    "            for pair in file_pairs:\n",
    "                filelist.append('_'.join(pair))\n",
    "                if c_type != 'models':\n",
    "                    filelist.append('_'.join(pair[::-1]))\n",
    "\n",
    "        # Maybe limit the number of videos for download\n",
    "        if num_videos is not None and num_videos > 0:\n",
    "            print('Downloading the first {} videos'.format(num_videos))\n",
    "            filelist = filelist[:num_videos]\n",
    "\n",
    "        # Server and local paths\n",
    "        dataset_videos_url = args.base_url + '{}/{}/{}/'.format(dataset_path, c_compression, c_type)\n",
    "        dataset_mask_url = args.base_url + '{}/{}/videos/'.format(dataset_path, 'masks')\n",
    "\n",
    "        if c_type == 'videos':\n",
    "            dataset_output_path = join(output_path, dataset_path, c_compression, c_type)\n",
    "            print('Output path: {}'.format(dataset_output_path))\n",
    "            filelist = [filename + '.mp4' for filename in filelist]\n",
    "            download_files(filelist, dataset_videos_url, dataset_output_path)\n",
    "        elif c_type == 'masks':\n",
    "            dataset_output_path = join(output_path, dataset_path, c_type, 'videos')\n",
    "            print('Output path: {}'.format(dataset_output_path))\n",
    "            filelist = [filename + '.png' for filename in filelist]\n",
    "            download_files(filelist, dataset_mask_url, dataset_output_path)\n",
    "        elif c_type == 'models':\n",
    "            if 'Deepfakes' in dataset:\n",
    "                print('Downloading the {} models for Deepfakes'.format(len(DEEPFAKES_MODEL_NAMES)))\n",
    "                dataset_output_path = join(output_path, dataset_path, c_compression, c_type)\n",
    "                print('Output path: {}'.format(dataset_output_path))\n",
    "                download_files(DEEPFAKES_MODEL_NAMES, args.deepfakes_model_url, dataset_output_path)\n",
    "            else:\n",
    "                print('No models to download for dataset {}'.format(dataset))\n",
    "                continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    main(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4dee304fe6656ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:43:34.068019Z",
     "start_time": "2024-09-01T19:42:38.797515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By pressing any key to continue you confirm that you have agreed to the FaceForensics terms of use as described at:\n",
      "http://canis.vc.in.tum.de:8100/webpage/FaceForensics_TOS.pdf\n",
      "***\n",
      "Press any key to continue, or CTRL-C to exit.\n",
      "Downloading videos of dataset \"original_sequences/youtube\"\n",
      "Failed to retrieve file list: <urlopen error [Errno 61] Connection refused>\n",
      "Please check your network connection or try a different server.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mConnectionRefusedError\u001B[0m                    Traceback (most recent call last)",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:1354\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1353\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1354\u001B[0m     \u001B[43mh\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1355\u001B[0m \u001B[43m              \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhas_header\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTransfer-encoding\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1356\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:1256\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1255\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1256\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:1302\u001B[0m, in \u001B[0;36mHTTPConnection._send_request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1301\u001B[0m     body \u001B[38;5;241m=\u001B[39m _encode(body, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbody\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1302\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mendheaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:1251\u001B[0m, in \u001B[0;36mHTTPConnection.endheaders\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1250\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CannotSendHeader()\n\u001B[0;32m-> 1251\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:1011\u001B[0m, in \u001B[0;36mHTTPConnection._send_output\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1010\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer[:]\n\u001B[0;32m-> 1011\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1013\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m message_body \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1014\u001B[0m \n\u001B[1;32m   1015\u001B[0m     \u001B[38;5;66;03m# create a consistent interface to message_body\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:951\u001B[0m, in \u001B[0;36mHTTPConnection.send\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    950\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_open:\n\u001B[0;32m--> 951\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    952\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:922\u001B[0m, in \u001B[0;36mHTTPConnection.connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    921\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 922\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_connection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msource_address\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock\u001B[38;5;241m.\u001B[39msetsockopt(socket\u001B[38;5;241m.\u001B[39mIPPROTO_TCP, socket\u001B[38;5;241m.\u001B[39mTCP_NODELAY, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/socket.py:808\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address)\u001B[0m\n\u001B[1;32m    807\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 808\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[1;32m    809\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    810\u001B[0m     \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/socket.py:796\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address)\u001B[0m\n\u001B[1;32m    795\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n\u001B[0;32m--> 796\u001B[0m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "\u001B[0;31mConnectionRefusedError\u001B[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mURLError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 165\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(args)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moriginal\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m dataset_path:\n\u001B[0;32m--> 165\u001B[0m     file_pairs \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(\u001B[43murllib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_url\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mFILELIST_URL\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mread()\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m    166\u001B[0m     filelist \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:222\u001B[0m, in \u001B[0;36murlopen\u001B[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[1;32m    221\u001B[0m     opener \u001B[38;5;241m=\u001B[39m _opener\n\u001B[0;32m--> 222\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mopener\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:525\u001B[0m, in \u001B[0;36mOpenerDirector.open\u001B[0;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[1;32m    524\u001B[0m sys\u001B[38;5;241m.\u001B[39maudit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124murllib.Request\u001B[39m\u001B[38;5;124m'\u001B[39m, req\u001B[38;5;241m.\u001B[39mfull_url, req\u001B[38;5;241m.\u001B[39mdata, req\u001B[38;5;241m.\u001B[39mheaders, req\u001B[38;5;241m.\u001B[39mget_method())\n\u001B[0;32m--> 525\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[38;5;66;03m# post-process response\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:542\u001B[0m, in \u001B[0;36mOpenerDirector._open\u001B[0;34m(self, req, data)\u001B[0m\n\u001B[1;32m    541\u001B[0m protocol \u001B[38;5;241m=\u001B[39m req\u001B[38;5;241m.\u001B[39mtype\n\u001B[0;32m--> 542\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_chain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_open\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\n\u001B[1;32m    543\u001B[0m \u001B[43m                          \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_open\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    544\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:502\u001B[0m, in \u001B[0;36mOpenerDirector._call_chain\u001B[0;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[1;32m    501\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(handler, meth_name)\n\u001B[0;32m--> 502\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:1383\u001B[0m, in \u001B[0;36mHTTPHandler.http_open\u001B[0;34m(self, req)\u001B[0m\n\u001B[1;32m   1382\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhttp_open\u001B[39m(\u001B[38;5;28mself\u001B[39m, req):\n\u001B[0;32m-> 1383\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhttp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mHTTPConnection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:1357\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1356\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n\u001B[0;32m-> 1357\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m URLError(err)\n\u001B[1;32m   1358\u001B[0m r \u001B[38;5;241m=\u001B[39m h\u001B[38;5;241m.\u001B[39mgetresponse()\n",
      "\u001B[0;31mURLError\u001B[0m: <urlopen error [Errno 61] Connection refused>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mSystemExit\u001B[0m                                Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "Cell \u001B[0;32mIn[23], line 213\u001B[0m\n\u001B[1;32m    212\u001B[0m args \u001B[38;5;241m=\u001B[39m parse_args()\n\u001B[0;32m--> 213\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[23], line 209\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(args)\u001B[0m\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease check your network connection or try a different server.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 209\u001B[0m \u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mSystemExit\u001B[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2095\u001B[0m, in \u001B[0;36mInteractiveShell.showtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2092\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m exception_only:\n\u001B[1;32m   2093\u001B[0m     stb \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAn exception has occurred, use \u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mtb to see \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   2094\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthe full traceback.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m-> 2095\u001B[0m     stb\u001B[38;5;241m.\u001B[39mextend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mInteractiveTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_exception_only\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2096\u001B[0m \u001B[43m                                                     \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   2097\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2098\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2099\u001B[0m         \u001B[38;5;66;03m# Exception classes can customise their traceback - we\u001B[39;00m\n\u001B[1;32m   2100\u001B[0m         \u001B[38;5;66;03m# use this in IPython.parallel for exceptions occurring\u001B[39;00m\n\u001B[1;32m   2101\u001B[0m         \u001B[38;5;66;03m# in the engines. This should return a list of strings.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/ultratb.py:696\u001B[0m, in \u001B[0;36mListTB.get_exception_only\u001B[0;34m(self, etype, value)\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_exception_only\u001B[39m(\u001B[38;5;28mself\u001B[39m, etype, value):\n\u001B[1;32m    689\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001B[39;00m\n\u001B[1;32m    690\u001B[0m \n\u001B[1;32m    691\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    694\u001B[0m \u001B[38;5;124;03m    value : exception value\u001B[39;00m\n\u001B[1;32m    695\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 696\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mListTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/ultratb.py:559\u001B[0m, in \u001B[0;36mListTB.structured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, context)\u001B[0m\n\u001B[1;32m    556\u001B[0m     chained_exc_ids\u001B[38;5;241m.\u001B[39madd(\u001B[38;5;28mid\u001B[39m(exception[\u001B[38;5;241m1\u001B[39m]))\n\u001B[1;32m    557\u001B[0m     chained_exceptions_tb_offset \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    558\u001B[0m     out_list \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 559\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    560\u001B[0m \u001B[43m            \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    561\u001B[0m \u001B[43m            \u001B[49m\u001B[43mevalue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    562\u001B[0m \u001B[43m            \u001B[49m\u001B[43m(\u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchained_exc_ids\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[1;32m    563\u001B[0m \u001B[43m            \u001B[49m\u001B[43mchained_exceptions_tb_offset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    564\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    565\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    566\u001B[0m         \u001B[38;5;241m+\u001B[39m chained_exception_message\n\u001B[1;32m    567\u001B[0m         \u001B[38;5;241m+\u001B[39m out_list)\n\u001B[1;32m    569\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out_list\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/ultratb.py:1396\u001B[0m, in \u001B[0;36mAutoFormattedTB.structured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1394\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1395\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtb \u001B[38;5;241m=\u001B[39m etb\n\u001B[0;32m-> 1396\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFormattedTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1397\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\n\u001B[1;32m   1398\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/ultratb.py:1287\u001B[0m, in \u001B[0;36mFormattedTB.structured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1284\u001B[0m mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode\n\u001B[1;32m   1285\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose_modes:\n\u001B[1;32m   1286\u001B[0m     \u001B[38;5;66;03m# Verbose modes need a full traceback\u001B[39;00m\n\u001B[0;32m-> 1287\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVerboseTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1288\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\n\u001B[1;32m   1289\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1290\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMinimal\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m   1291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ListTB\u001B[38;5;241m.\u001B[39mget_exception_only(\u001B[38;5;28mself\u001B[39m, etype, value)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/ultratb.py:1140\u001B[0m, in \u001B[0;36mVerboseTB.structured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstructured_traceback\u001B[39m(\n\u001B[1;32m   1132\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1133\u001B[0m     etype: \u001B[38;5;28mtype\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1137\u001B[0m     number_of_lines_of_context: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m,\n\u001B[1;32m   1138\u001B[0m ):\n\u001B[1;32m   1139\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1140\u001B[0m     formatted_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_exception_as_a_whole\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1141\u001B[0m \u001B[43m                                                           \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1143\u001B[0m     colors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mColors  \u001B[38;5;66;03m# just a shorthand + quicker name lookup\u001B[39;00m\n\u001B[1;32m   1144\u001B[0m     colorsnormal \u001B[38;5;241m=\u001B[39m colors\u001B[38;5;241m.\u001B[39mNormal  \u001B[38;5;66;03m# used a lot\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/ultratb.py:1030\u001B[0m, in \u001B[0;36mVerboseTB.format_exception_as_a_whole\u001B[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m   1027\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(tb_offset, \u001B[38;5;28mint\u001B[39m)\n\u001B[1;32m   1028\u001B[0m head \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_header(\u001B[38;5;28mstr\u001B[39m(etype), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlong_header)\n\u001B[1;32m   1029\u001B[0m records \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m-> 1030\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_records\u001B[49m\u001B[43m(\u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m etb \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[1;32m   1031\u001B[0m )\n\u001B[1;32m   1033\u001B[0m frames \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m   1034\u001B[0m skipped \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/ultratb.py:1098\u001B[0m, in \u001B[0;36mVerboseTB.get_records\u001B[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m   1096\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m cf \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1097\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1098\u001B[0m         mod \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39mgetmodule(\u001B[43mcf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtb_frame\u001B[49m)\n\u001B[1;32m   1099\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m mod \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1100\u001B[0m             mod_name \u001B[38;5;241m=\u001B[39m mod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import urllib.request\n",
    "import tempfile\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "from urllib.error import URLError\n",
    "\n",
    "# URLs and filenames\n",
    "FILELIST_URL = 'misc/filelist.json'\n",
    "DEEPFAKES_DETECTION_URL = 'misc/deepfake_detection_filenames.json'\n",
    "DEEPFAKES_MODEL_NAMES = ['decoder_A.h5', 'decoder_B.h5', 'encoder.h5']\n",
    "\n",
    "# Parameters\n",
    "DATASETS = {\n",
    "    'original_youtube_videos': 'misc/downloaded_youtube_videos.zip',\n",
    "    'original_youtube_videos_info': 'misc/downloaded_youtube_videos_info.zip',\n",
    "    'original': 'original_sequences/youtube',\n",
    "    'DeepFakeDetection_original': 'original_sequences/actors',\n",
    "    'Deepfakes': 'manipulated_sequences/Deepfakes',\n",
    "    'DeepFakeDetection': 'manipulated_sequences/DeepFakeDetection',\n",
    "    'Face2Face': 'manipulated_sequences/Face2Face',\n",
    "    'FaceShifter': 'manipulated_sequences/FaceShifter',\n",
    "    'FaceSwap': 'manipulated_sequences/FaceSwap',\n",
    "    'NeuralTextures': 'manipulated_sequences/NeuralTextures'\n",
    "}\n",
    "ALL_DATASETS = ['original', 'DeepFakeDetection_original', 'Deepfakes',\n",
    "                'DeepFakeDetection', 'Face2Face', 'FaceShifter', 'FaceSwap',\n",
    "                'NeuralTextures']\n",
    "COMPRESSION = ['raw', 'c23', 'c40']\n",
    "TYPE = ['videos', 'masks', 'models']\n",
    "SERVERS = ['EU', 'EU2', 'CA']\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Downloads FaceForensics v2 public data release.',\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
    "    )\n",
    "    parser.add_argument('output_path', type=str, help='Output directory.')\n",
    "    parser.add_argument('-d', '--dataset', type=str, default='all',\n",
    "                        help='Which dataset to download.',\n",
    "                        choices=list(DATASETS.keys()) + ['all'])\n",
    "    parser.add_argument('-c', '--compression', type=str, default='raw',\n",
    "                        help='Which compression degree.',\n",
    "                        choices=COMPRESSION)\n",
    "    parser.add_argument('-t', '--type', type=str, default='videos',\n",
    "                        help='Which file type.',\n",
    "                        choices=TYPE)\n",
    "    parser.add_argument('-n', '--num_videos', type=int, default=None,\n",
    "                        help='Number of videos to download.')\n",
    "    parser.add_argument('--server', type=str, default='EU',\n",
    "                        help='Server to download from.',\n",
    "                        choices=SERVERS)\n",
    "    parser.add_argument('--retry', type=int, default=3,\n",
    "                        help='Number of retries if a download fails.')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # URLs\n",
    "    server = args.server\n",
    "    if server == 'EU':\n",
    "        args.base_url = 'http://canis.vc.in.tum.de:8100/v3/'\n",
    "    elif server == 'EU2':\n",
    "        args.base_url = 'http://kaldir.vc.in.tum.de/faceforensics/v3/'\n",
    "    elif server == 'CA':\n",
    "        args.base_url = 'http://falas.cmpt.sfu.ca:8100/v3/'\n",
    "    else:\n",
    "        raise Exception('Wrong server name. Choices: {}'.format(str(SERVERS)))\n",
    "\n",
    "    args.tos_url = args.base_url.replace('v3/', 'webpage/FaceForensics_TOS.pdf')\n",
    "    args.deepfakes_model_url = args.base_url + 'manipulated_sequences/Deepfakes/models/'\n",
    "\n",
    "    return args\n",
    "\n",
    "def download_files(filenames, base_url, output_path, retry_limit=3):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    filenames = tqdm(filenames)\n",
    "    for filename in filenames:\n",
    "        success = False\n",
    "        for attempt in range(retry_limit):\n",
    "            try:\n",
    "                download_file(base_url + filename, join(output_path, filename))\n",
    "                success = True\n",
    "                break\n",
    "            except (URLError, ConnectionRefusedError) as e:\n",
    "                print(f\"Error downloading {filename}: {e}. Retrying ({attempt + 1}/{retry_limit})...\")\n",
    "                time.sleep(2)  # Wait before retrying\n",
    "        if not success:\n",
    "            print(f\"Failed to download {filename} after {retry_limit} attempts.\")\n",
    "\n",
    "def reporthook(count, block_size, total_size):\n",
    "    global start_time\n",
    "    if count == 0:\n",
    "        start_time = time.time()\n",
    "        return\n",
    "    duration = time.time() - start_time\n",
    "    progress_size = int(count * block_size)\n",
    "    speed = int(progress_size / (1024 * duration))\n",
    "    percent = int(count * block_size * 100 / total_size)\n",
    "    sys.stdout.write(\"\\rProgress: %d%%, %d MB, %d KB/s, %d seconds passed\" %\n",
    "                     (percent, progress_size / (1024 * 1024), speed, duration))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def download_file(url, out_file, report_progress=False):\n",
    "    out_dir = os.path.dirname(out_file)\n",
    "    if not os.path.isfile(out_file):\n",
    "        fh, out_file_tmp = tempfile.mkstemp(dir=out_dir)\n",
    "        f = os.fdopen(fh, 'w')\n",
    "        f.close()\n",
    "        if report_progress:\n",
    "            urllib.request.urlretrieve(url, out_file_tmp, reporthook=reporthook)\n",
    "        else:\n",
    "            urllib.request.urlretrieve(url, out_file_tmp)\n",
    "        os.rename(out_file_tmp, out_file)\n",
    "    else:\n",
    "        tqdm.write('WARNING: skipping download of existing file ' + out_file)\n",
    "\n",
    "def main(args):\n",
    "    # TOS\n",
    "    print('By pressing any key to continue you confirm that you have agreed ' \\\n",
    "          'to the FaceForensics terms of use as described at:')\n",
    "    print(args.tos_url)\n",
    "    print('***')\n",
    "    print('Press any key to continue, or CTRL-C to exit.')\n",
    "    _ = input('')\n",
    "\n",
    "    # Extract arguments\n",
    "    c_datasets = [args.dataset] if args.dataset != 'all' else ALL_DATASETS\n",
    "    c_type = args.type\n",
    "    c_compression = args.compression\n",
    "    num_videos = args.num_videos\n",
    "    output_path = args.output_path\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Check for special dataset cases\n",
    "    for dataset in c_datasets:\n",
    "        dataset_path = DATASETS[dataset]\n",
    "        # Special cases\n",
    "        if 'original_youtube_videos' in dataset:\n",
    "            print('Downloading original youtube videos.')\n",
    "            if not 'info' in dataset_path:\n",
    "                print('Please be patient, this may take a while (~40gb)')\n",
    "                suffix = ''\n",
    "            else:\n",
    "                suffix = 'info'\n",
    "            download_file(args.base_url + dataset_path,\n",
    "                          out_file=join(output_path, 'downloaded_videos{}.zip'.format(suffix)),\n",
    "                          report_progress=True)\n",
    "            return\n",
    "\n",
    "        # Else: regular datasets\n",
    "        print('Downloading {} of dataset \"{}\"'.format(c_type, dataset_path))\n",
    "\n",
    "        # Get filelists and video lengths list from server\n",
    "        try:\n",
    "            if 'DeepFakeDetection' in dataset_path or 'actors' in dataset_path:\n",
    "                filepaths = json.loads(urllib.request.urlopen(args.base_url + DEEPFAKES_DETECTION_URL).read().decode(\"utf-8\"))\n",
    "                if 'actors' in dataset_path:\n",
    "                    filelist = filepaths['actors']\n",
    "                else:\n",
    "                    filelist = filepaths['DeepFakesDetection']\n",
    "            elif 'original' in dataset_path:\n",
    "                file_pairs = json.loads(urllib.request.urlopen(args.base_url + FILELIST_URL).read().decode(\"utf-8\"))\n",
    "                filelist = []\n",
    "                for pair in file_pairs:\n",
    "                    filelist += pair\n",
    "            else:\n",
    "                file_pairs = json.loads(urllib.request.urlopen(args.base_url + FILELIST_URL).read().decode(\"utf-8\"))\n",
    "                filelist = []\n",
    "                for pair in file_pairs:\n",
    "                    filelist.append('_'.join(pair))\n",
    "                    if c_type != 'models':\n",
    "                        filelist.append('_'.join(pair[::-1]))\n",
    "\n",
    "            # Maybe limit the number of videos for download\n",
    "            if num_videos is not None and num_videos > 0:\n",
    "                print('Downloading the first {} videos'.format(num_videos))\n",
    "                filelist = filelist[:num_videos]\n",
    "\n",
    "            # Server and local paths\n",
    "            dataset_videos_url = args.base_url + '{}/{}/{}/'.format(dataset_path, c_compression, c_type)\n",
    "            dataset_mask_url = args.base_url + '{}/{}/videos/'.format(dataset_path, 'masks')\n",
    "\n",
    "            if c_type == 'videos':\n",
    "                dataset_output_path = join(output_path, dataset_path, c_compression, c_type)\n",
    "                print('Output path: {}'.format(dataset_output_path))\n",
    "                filelist = [filename + '.mp4' for filename in filelist]\n",
    "                download_files(filelist, dataset_videos_url, dataset_output_path, retry_limit=args.retry)\n",
    "            elif c_type == 'masks':\n",
    "                dataset_output_path = join(output_path, dataset_path, c_type, 'videos')\n",
    "                print('Output path: {}'.format(dataset_output_path))\n",
    "                filelist = [filename + '.png' for filename in filelist]\n",
    "                download_files(filelist, dataset_mask_url, dataset_output_path, retry_limit=args.retry)\n",
    "            elif c_type == 'models':\n",
    "                if 'Deepfakes' in dataset:\n",
    "                    print('Downloading the {} models for Deepfakes'.format(len(DEEPFAKES_MODEL_NAMES)))\n",
    "                    dataset_output_path = join(output_path, dataset_path, c_compression, c_type)\n",
    "                    print('Output path: {}'.format(dataset_output_path))\n",
    "                    download_files(DEEPFAKES_MODEL_NAMES, args.deepfakes_model_url, dataset_output_path, retry_limit=args.retry)\n",
    "                else:\n",
    "                    raise Exception('No model files exist for dataset \"{}\"'.format(dataset))\n",
    "            else:\n",
    "                raise Exception('Unknown data type \"{}\"'.format(c_type))\n",
    "        except URLError as e:\n",
    "            print(f\"Failed to retrieve file list: {e}\")\n",
    "            print(\"Please check your network connection or try a different server.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e2e263173ebe22d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:43:57.580867Z",
     "start_time": "2024-09-01T19:43:51.460179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By pressing any key to continue you confirm that you have agreed to the FaceForensics terms of use as described at:\n",
      "http://canis.vc.in.tum.de:8100/webpage/FaceForensics_TOS.pdf\n",
      "***\n",
      "Press any key to continue, or CTRL-C to exit.\n",
      "Downloading videos of dataset \"original_sequences/youtube\"\n",
      "Failed to retrieve file list: <urlopen error [Errno 61] Connection refused>\n",
      "Please check your network connection or try a different server.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py\", line 1354, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py\", line 1256, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py\", line 1302, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py\", line 1251, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py\", line 1011, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py\", line 951, in send\n",
      "    self.connect()\n",
      "  File \"/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py\", line 922, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/opt/anaconda3/envs/untitled/lib/python3.8/socket.py\", line 808, in create_connection\n",
      "    raise err\n",
      "  File \"/opt/anaconda3/envs/untitled/lib/python3.8/socket.py\", line 796, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/jd/5vc1z8913t55htnkf031mprw0000gn/T/ipykernel_5519/1756550440.py\", line 49, in main\n",
      "    file_pairs = json.loads(urllib.request.urlopen(args.base_url + FILELIST_URL).read().decode(\"utf-8\"))\n",
      "  File \"/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py\", line 222, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py\", line 542, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "  File \"/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py\", line 502, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py\", line 1383, in http_open\n",
      "    return self.do_open(http.client.HTTPConnection, req)\n",
      "  File \"/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py\", line 1357, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [Errno 61] Connection refused>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mConnectionRefusedError\u001B[0m                    Traceback (most recent call last)",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:1354\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1353\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1354\u001B[0m     \u001B[43mh\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1355\u001B[0m \u001B[43m              \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhas_header\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTransfer-encoding\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1356\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:1256\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1255\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1256\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:1302\u001B[0m, in \u001B[0;36mHTTPConnection._send_request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1301\u001B[0m     body \u001B[38;5;241m=\u001B[39m _encode(body, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbody\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1302\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mendheaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:1251\u001B[0m, in \u001B[0;36mHTTPConnection.endheaders\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1250\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CannotSendHeader()\n\u001B[0;32m-> 1251\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:1011\u001B[0m, in \u001B[0;36mHTTPConnection._send_output\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1010\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer[:]\n\u001B[0;32m-> 1011\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1013\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m message_body \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1014\u001B[0m \n\u001B[1;32m   1015\u001B[0m     \u001B[38;5;66;03m# create a consistent interface to message_body\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:951\u001B[0m, in \u001B[0;36mHTTPConnection.send\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    950\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_open:\n\u001B[0;32m--> 951\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    952\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/http/client.py:922\u001B[0m, in \u001B[0;36mHTTPConnection.connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    921\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 922\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_connection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msource_address\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock\u001B[38;5;241m.\u001B[39msetsockopt(socket\u001B[38;5;241m.\u001B[39mIPPROTO_TCP, socket\u001B[38;5;241m.\u001B[39mTCP_NODELAY, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/socket.py:808\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address)\u001B[0m\n\u001B[1;32m    807\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 808\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[1;32m    809\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    810\u001B[0m     \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/socket.py:796\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address)\u001B[0m\n\u001B[1;32m    795\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n\u001B[0;32m--> 796\u001B[0m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "\u001B[0;31mConnectionRefusedError\u001B[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mURLError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 49\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(args)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moriginal\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m dataset_path:\n\u001B[0;32m---> 49\u001B[0m     file_pairs \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(\u001B[43murllib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_url\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mFILELIST_URL\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mread()\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m     50\u001B[0m     filelist \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:222\u001B[0m, in \u001B[0;36murlopen\u001B[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[1;32m    221\u001B[0m     opener \u001B[38;5;241m=\u001B[39m _opener\n\u001B[0;32m--> 222\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mopener\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:525\u001B[0m, in \u001B[0;36mOpenerDirector.open\u001B[0;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[1;32m    524\u001B[0m sys\u001B[38;5;241m.\u001B[39maudit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124murllib.Request\u001B[39m\u001B[38;5;124m'\u001B[39m, req\u001B[38;5;241m.\u001B[39mfull_url, req\u001B[38;5;241m.\u001B[39mdata, req\u001B[38;5;241m.\u001B[39mheaders, req\u001B[38;5;241m.\u001B[39mget_method())\n\u001B[0;32m--> 525\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[38;5;66;03m# post-process response\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:542\u001B[0m, in \u001B[0;36mOpenerDirector._open\u001B[0;34m(self, req, data)\u001B[0m\n\u001B[1;32m    541\u001B[0m protocol \u001B[38;5;241m=\u001B[39m req\u001B[38;5;241m.\u001B[39mtype\n\u001B[0;32m--> 542\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_chain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_open\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\n\u001B[1;32m    543\u001B[0m \u001B[43m                          \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_open\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    544\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:502\u001B[0m, in \u001B[0;36mOpenerDirector._call_chain\u001B[0;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[1;32m    501\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(handler, meth_name)\n\u001B[0;32m--> 502\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:1383\u001B[0m, in \u001B[0;36mHTTPHandler.http_open\u001B[0;34m(self, req)\u001B[0m\n\u001B[1;32m   1382\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhttp_open\u001B[39m(\u001B[38;5;28mself\u001B[39m, req):\n\u001B[0;32m-> 1383\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhttp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mHTTPConnection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/urllib/request.py:1357\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1356\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n\u001B[0;32m-> 1357\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m URLError(err)\n\u001B[1;32m   1358\u001B[0m r \u001B[38;5;241m=\u001B[39m h\u001B[38;5;241m.\u001B[39mgetresponse()\n",
      "\u001B[0;31mURLError\u001B[0m: <urlopen error [Errno 61] Connection refused>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mSystemExit\u001B[0m                                Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "Cell \u001B[0;32mIn[24], line 102\u001B[0m\n\u001B[1;32m    101\u001B[0m args \u001B[38;5;241m=\u001B[39m parse_args()\n\u001B[0;32m--> 102\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[24], line 94\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(args)\u001B[0m\n\u001B[1;32m     93\u001B[0m             traceback\u001B[38;5;241m.\u001B[39mprint_exc()\n\u001B[0;32m---> 94\u001B[0m             \u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mSystemExit\u001B[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2095\u001B[0m, in \u001B[0;36mInteractiveShell.showtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2092\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m exception_only:\n\u001B[1;32m   2093\u001B[0m     stb \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAn exception has occurred, use \u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mtb to see \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   2094\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthe full traceback.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m-> 2095\u001B[0m     stb\u001B[38;5;241m.\u001B[39mextend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mInteractiveTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_exception_only\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2096\u001B[0m \u001B[43m                                                     \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   2097\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2098\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2099\u001B[0m         \u001B[38;5;66;03m# Exception classes can customise their traceback - we\u001B[39;00m\n\u001B[1;32m   2100\u001B[0m         \u001B[38;5;66;03m# use this in IPython.parallel for exceptions occurring\u001B[39;00m\n\u001B[1;32m   2101\u001B[0m         \u001B[38;5;66;03m# in the engines. This should return a list of strings.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/ultratb.py:696\u001B[0m, in \u001B[0;36mListTB.get_exception_only\u001B[0;34m(self, etype, value)\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_exception_only\u001B[39m(\u001B[38;5;28mself\u001B[39m, etype, value):\n\u001B[1;32m    689\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001B[39;00m\n\u001B[1;32m    690\u001B[0m \n\u001B[1;32m    691\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    694\u001B[0m \u001B[38;5;124;03m    value : exception value\u001B[39;00m\n\u001B[1;32m    695\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 696\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mListTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/ultratb.py:559\u001B[0m, in \u001B[0;36mListTB.structured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, context)\u001B[0m\n\u001B[1;32m    556\u001B[0m     chained_exc_ids\u001B[38;5;241m.\u001B[39madd(\u001B[38;5;28mid\u001B[39m(exception[\u001B[38;5;241m1\u001B[39m]))\n\u001B[1;32m    557\u001B[0m     chained_exceptions_tb_offset \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    558\u001B[0m     out_list \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 559\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    560\u001B[0m \u001B[43m            \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    561\u001B[0m \u001B[43m            \u001B[49m\u001B[43mevalue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    562\u001B[0m \u001B[43m            \u001B[49m\u001B[43m(\u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchained_exc_ids\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[1;32m    563\u001B[0m \u001B[43m            \u001B[49m\u001B[43mchained_exceptions_tb_offset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    564\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    565\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    566\u001B[0m         \u001B[38;5;241m+\u001B[39m chained_exception_message\n\u001B[1;32m    567\u001B[0m         \u001B[38;5;241m+\u001B[39m out_list)\n\u001B[1;32m    569\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out_list\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/ultratb.py:1396\u001B[0m, in \u001B[0;36mAutoFormattedTB.structured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1394\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1395\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtb \u001B[38;5;241m=\u001B[39m etb\n\u001B[0;32m-> 1396\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFormattedTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1397\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\n\u001B[1;32m   1398\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/ultratb.py:1287\u001B[0m, in \u001B[0;36mFormattedTB.structured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1284\u001B[0m mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode\n\u001B[1;32m   1285\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose_modes:\n\u001B[1;32m   1286\u001B[0m     \u001B[38;5;66;03m# Verbose modes need a full traceback\u001B[39;00m\n\u001B[0;32m-> 1287\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVerboseTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1288\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\n\u001B[1;32m   1289\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1290\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMinimal\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m   1291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ListTB\u001B[38;5;241m.\u001B[39mget_exception_only(\u001B[38;5;28mself\u001B[39m, etype, value)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/ultratb.py:1140\u001B[0m, in \u001B[0;36mVerboseTB.structured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstructured_traceback\u001B[39m(\n\u001B[1;32m   1132\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1133\u001B[0m     etype: \u001B[38;5;28mtype\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1137\u001B[0m     number_of_lines_of_context: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m,\n\u001B[1;32m   1138\u001B[0m ):\n\u001B[1;32m   1139\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1140\u001B[0m     formatted_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_exception_as_a_whole\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1141\u001B[0m \u001B[43m                                                           \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1143\u001B[0m     colors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mColors  \u001B[38;5;66;03m# just a shorthand + quicker name lookup\u001B[39;00m\n\u001B[1;32m   1144\u001B[0m     colorsnormal \u001B[38;5;241m=\u001B[39m colors\u001B[38;5;241m.\u001B[39mNormal  \u001B[38;5;66;03m# used a lot\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/ultratb.py:1030\u001B[0m, in \u001B[0;36mVerboseTB.format_exception_as_a_whole\u001B[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m   1027\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(tb_offset, \u001B[38;5;28mint\u001B[39m)\n\u001B[1;32m   1028\u001B[0m head \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_header(\u001B[38;5;28mstr\u001B[39m(etype), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlong_header)\n\u001B[1;32m   1029\u001B[0m records \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m-> 1030\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_records\u001B[49m\u001B[43m(\u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m etb \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[1;32m   1031\u001B[0m )\n\u001B[1;32m   1033\u001B[0m frames \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m   1034\u001B[0m skipped \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/untitled/lib/python3.8/site-packages/IPython/core/ultratb.py:1098\u001B[0m, in \u001B[0;36mVerboseTB.get_records\u001B[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m   1096\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m cf \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1097\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1098\u001B[0m         mod \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39mgetmodule(\u001B[43mcf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtb_frame\u001B[49m)\n\u001B[1;32m   1099\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m mod \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1100\u001B[0m             mod_name \u001B[38;5;241m=\u001B[39m mod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "\n",
    "def main(args):\n",
    "    try:\n",
    "        # TOS\n",
    "        print('By pressing any key to continue you confirm that you have agreed ' \\\n",
    "              'to the FaceForensics terms of use as described at:')\n",
    "        print(args.tos_url)\n",
    "        print('***')\n",
    "        print('Press any key to continue, or CTRL-C to exit.')\n",
    "        _ = input('')\n",
    "\n",
    "        # Extract arguments\n",
    "        c_datasets = [args.dataset] if args.dataset != 'all' else ALL_DATASETS\n",
    "        c_type = args.type\n",
    "        c_compression = args.compression\n",
    "        num_videos = args.num_videos\n",
    "        output_path = args.output_path\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "        # Check for special dataset cases\n",
    "        for dataset in c_datasets:\n",
    "            dataset_path = DATASETS[dataset]\n",
    "            # Special cases\n",
    "            if 'original_youtube_videos' in dataset:\n",
    "                print('Downloading original youtube videos.')\n",
    "                if not 'info' in dataset_path:\n",
    "                    print('Please be patient, this may take a while (~40gb)')\n",
    "                    suffix = ''\n",
    "                else:\n",
    "                    suffix = 'info'\n",
    "                download_file(args.base_url + dataset_path,\n",
    "                              out_file=join(output_path, 'downloaded_videos{}.zip'.format(suffix)),\n",
    "                              report_progress=True)\n",
    "                return\n",
    "\n",
    "            # Else: regular datasets\n",
    "            print('Downloading {} of dataset \"{}\"'.format(c_type, dataset_path))\n",
    "\n",
    "            # Get filelists and video lengths list from server\n",
    "            try:\n",
    "                if 'DeepFakeDetection' in dataset_path or 'actors' in dataset_path:\n",
    "                    filepaths = json.loads(urllib.request.urlopen(args.base_url + DEEPFAKES_DETECTION_URL).read().decode(\"utf-8\"))\n",
    "                    if 'actors' in dataset_path:\n",
    "                        filelist = filepaths['actors']\n",
    "                    else:\n",
    "                        filelist = filepaths['DeepFakesDetection']\n",
    "                elif 'original' in dataset_path:\n",
    "                    file_pairs = json.loads(urllib.request.urlopen(args.base_url + FILELIST_URL).read().decode(\"utf-8\"))\n",
    "                    filelist = []\n",
    "                    for pair in file_pairs:\n",
    "                        filelist += pair\n",
    "                else:\n",
    "                    file_pairs = json.loads(urllib.request.urlopen(args.base_url + FILELIST_URL).read().decode(\"utf-8\"))\n",
    "                    filelist = []\n",
    "                    for pair in file_pairs:\n",
    "                        filelist.append('_'.join(pair))\n",
    "                        if c_type != 'models':\n",
    "                            filelist.append('_'.join(pair[::-1]))\n",
    "\n",
    "                # Maybe limit the number of videos for download\n",
    "                if num_videos is not None and num_videos > 0:\n",
    "                    print('Downloading the first {} videos'.format(num_videos))\n",
    "                    filelist = filelist[:num_videos]\n",
    "\n",
    "                # Server and local paths\n",
    "                dataset_videos_url = args.base_url + '{}/{}/{}/'.format(dataset_path, c_compression, c_type)\n",
    "                dataset_mask_url = args.base_url + '{}/{}/videos/'.format(dataset_path, 'masks')\n",
    "\n",
    "                if c_type == 'videos':\n",
    "                    dataset_output_path = join(output_path, dataset_path, c_compression, c_type)\n",
    "                    print('Output path: {}'.format(dataset_output_path))\n",
    "                    filelist = [filename + '.mp4' for filename in filelist]\n",
    "                    download_files(filelist, dataset_videos_url, dataset_output_path, retry_limit=args.retry)\n",
    "                elif c_type == 'masks':\n",
    "                    dataset_output_path = join(output_path, dataset_path, c_type, 'videos')\n",
    "                    print('Output path: {}'.format(dataset_output_path))\n",
    "                    filelist = [filename + '.png' for filename in filelist]\n",
    "                    download_files(filelist, dataset_mask_url, dataset_output_path, retry_limit=args.retry)\n",
    "                elif c_type == 'models':\n",
    "                    if 'Deepfakes' in dataset:\n",
    "                        print('Downloading the {} models for Deepfakes'.format(len(DEEPFAKES_MODEL_NAMES)))\n",
    "                        dataset_output_path = join(output_path, dataset_path, c_compression, c_type)\n",
    "                        print('Output path: {}'.format(dataset_output_path))\n",
    "                        download_files(DEEPFAKES_MODEL_NAMES, args.deepfakes_model_url, dataset_output_path, retry_limit=args.retry)\n",
    "                    else:\n",
    "                        raise Exception('No model files exist for dataset \"{}\"'.format(dataset))\n",
    "                else:\n",
    "                    raise Exception('Unknown data type \"{}\"'.format(c_type))\n",
    "            except URLError as e:\n",
    "                print(f\"Failed to retrieve file list: {e}\")\n",
    "                print(\"Please check your network connection or try a different server.\")\n",
    "                traceback.print_exc()\n",
    "                sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        traceback.print_exc()\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395730d1fcabbba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yt-dlp\n",
      "  Downloading yt_dlp-2024.8.6-py3-none-any.whl.metadata (170 kB)\n",
      "Requirement already satisfied: brotli in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from yt-dlp) (1.0.9)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from yt-dlp) (2024.7.4)\n",
      "Collecting mutagen (from yt-dlp)\n",
      "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pycryptodomex (from yt-dlp)\n",
      "  Downloading pycryptodomex-3.20.0-cp35-abi3-macosx_10_9_universal2.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.32.2 in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from yt-dlp) (2.32.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.17 in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from yt-dlp) (2.2.2)\n",
      "Collecting websockets>=12.0 (from yt-dlp)\n",
      "  Downloading websockets-13.0.1-cp38-cp38-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from requests<3,>=2.32.2->yt-dlp) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/untitled/lib/python3.8/site-packages (from requests<3,>=2.32.2->yt-dlp) (3.7)\n",
      "Downloading yt_dlp-2024.8.6-py3-none-any.whl (3.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.1/3.1 MB\u001B[0m \u001B[31m74.2 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:04\u001B[0m\n",
      "\u001B[?25hDownloading websockets-13.0.1-cp38-cp38-macosx_11_0_arm64.whl (148 kB)\n",
      "Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
      "Downloading pycryptodomex-3.20.0-cp35-abi3-macosx_10_9_universal2.whl (2.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m69.6 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:02\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: websockets, pycryptodomex, mutagen, yt-dlp\n",
      "Successfully installed mutagen-1.47.0 pycryptodomex-3.20.0 websockets-13.0.1 yt-dlp-2024.8.6\n"
     ]
    }
   ],
   "source": [
    "!pip install yt-dlp\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "eb34e584368bd290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:57:56.620416Z",
     "start_time": "2024-09-01T19:57:56.143734Z"
    }
   },
   "source": "!pip uninstall -y youtube-dl\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: youtube-dl 2021.12.17\r\n",
      "Uninstalling youtube-dl-2021.12.17:\r\n",
      "  Successfully uninstalled youtube-dl-2021.12.17\r\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcd9caf2b02e2e26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:50:29.607203Z",
     "start_time": "2024-09-01T19:50:27.074448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] iqji2dEX7No: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to extract uploader id; please report this issue on https://yt-dl.org/bug . Make sure you are using the latest version; see  https://yt-dl.org/update  on how to update. Be sure to call youtube-dl with the --verbose flag and include its complete output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] FYEGvuVWW0o: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to extract uploader id; please report this issue on https://yt-dl.org/bug . Make sure you are using the latest version; see  https://yt-dl.org/update  on how to update. Be sure to call youtube-dl with the --verbose flag and include its complete output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] 5WECsbqAQSk: Downloading webpage\n",
      "Videos downloaded to: test_videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to extract uploader id; please report this issue on https://yt-dl.org/bug . Make sure you are using the latest version; see  https://yt-dl.org/update  on how to update. Be sure to call youtube-dl with the --verbose flag and include its complete output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = \"test_videos\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List of YouTube video URLs to download\n",
    "video_urls = [\n",
    "    \"https://youtu.be/iqji2dEX7No?si=o9Ga2uGePRJrFRwX\",  # Sample Video 1\n",
    "    \"https://youtu.be/FYEGvuVWW0o?si=ty4187Vpb94ghhJt\",  # Sample Video 2\n",
    "    \"https://youtu.be/5WECsbqAQSk?si=coQZ0h30kGirwAOh\"   # Sample Video 3\n",
    "]\n",
    "\n",
    "# Download command using youtube-dl\n",
    "download_command = \"youtube-dl -f mp4 -o '{}/%(title)s.%(ext)s' \".format(output_dir)\n",
    "\n",
    "# Download each video\n",
    "for url in video_urls:\n",
    "    os.system(download_command + url)\n",
    "\n",
    "print(\"Videos downloaded to:\", output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "443a05c14ae72635",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T20:01:01.097328Z",
     "start_time": "2024-09-01T20:00:35.474632Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = \"test_videos\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List of YouTube video URLs to download\n",
    "video_urls = [\n",
    "    \"https://youtu.be/iqji2dEX7No?si=o9Ga2uGePRJrFRwX\",  # Sample Video 1\n",
    "    \"https://youtu.be/FYEGvuVWW0o?si=ty4187Vpb94ghhJt\",  # Sample Video 2\n",
    "    \"https://youtu.be/5WECsbqAQSk?si=coQZ0h30kGirwAOh\"\n",
    "]\n",
    "\n",
    "# Download command using yt-dlp\n",
    "download_command = \"yt-dlp -f mp4 -o '{}/%(title)s.%(ext)s' \".format(output_dir)\n",
    "\n",
    "# Download each video\n",
    "for url in video_urls:\n",
    "    os.system(download_command + url)\n",
    "\n",
    "print(\"Videos downloaded to:\", output_dir)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://youtu.be/iqji2dEX7No?si=o9Ga2uGePRJrFRwX\n",
      "[youtube] iqji2dEX7No: Downloading webpage\n",
      "[youtube] iqji2dEX7No: Downloading ios player API JSON\n",
      "[youtube] iqji2dEX7No: Downloading web creator player API JSON\n",
      "[youtube] iqji2dEX7No: Downloading m3u8 information\n",
      "[info] iqji2dEX7No: Downloading 1 format(s): 18\n",
      "[download] test_videos/Deepfake Example Presented by Senator Richard Blumenthal.mp4 has already been downloaded\n",
      "[download] 100% of    3.25MiB\n",
      "[youtube] Extracting URL: https://youtu.be/FYEGvuVWW0o?si=ty4187Vpb94ghhJt\n",
      "[youtube] FYEGvuVWW0o: Downloading webpage\n",
      "[youtube] FYEGvuVWW0o: Downloading ios player API JSON\n",
      "[youtube] FYEGvuVWW0o: Downloading web creator player API JSON\n",
      "[youtube] FYEGvuVWW0o: Downloading m3u8 information\n",
      "[info] FYEGvuVWW0o: Downloading 1 format(s): 18\n",
      "[download] Destination: test_videos/Deepfake Scam Example Featuring Martin Lewis.mp4\n",
      "[download] 100% of  657.62KiB in 00:00:03 at 187.53KiB/s \n",
      "[youtube] Extracting URL: https://youtu.be/5WECsbqAQSk?si=coQZ0h30kGirwAOh\n",
      "[youtube] 5WECsbqAQSk: Downloading webpage\n",
      "[youtube] 5WECsbqAQSk: Downloading ios player API JSON\n",
      "[youtube] 5WECsbqAQSk: Downloading web creator player API JSON\n",
      "[youtube] 5WECsbqAQSk: Downloading m3u8 information\n",
      "[info] 5WECsbqAQSk: Downloading 1 format(s): 18\n",
      "[download] Destination: test_videos/Supporting Local Retailers This Diwali ｜ Not Just A Cadbury Ad Campaign Video.mp4\n",
      "[download] 100% of    4.92MiB in 00:00:15 at 317.99KiB/s   \n",
      "Videos downloaded to: test_videos\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T20:18:18.081453Z",
     "start_time": "2024-09-01T20:18:18.053129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "\n",
    "def resize_frame(frame, scale_factor=0.5):\n",
    "    height, width = frame.shape[:2]\n",
    "    new_size = (int(width * scale_factor), int(height * scale_factor))\n",
    "    resized_frame = cv2.resize(frame, new_size)\n",
    "    return resized_frame\n",
    "\n",
    "def apply_ela(image_path, output_path, scale_factor=0.5):\n",
    "    original = Image.open(image_path)\n",
    "    original = original.convert(\"RGB\")\n",
    "\n",
    "    # Resize image\n",
    "    resized = original.resize((int(original.width * scale_factor), int(original.height * scale_factor)), Image.ANTIALIAS)\n",
    "\n",
    "    # Save resized image\n",
    "    resized.save(\"resized_image.png\")\n",
    "\n",
    "    # Reopen resized image\n",
    "    resized = Image.open(\"resized_image.png\")\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    original_np = np.array(original)\n",
    "    resized_np = np.array(resized)\n",
    "\n",
    "    # Calculate error level\n",
    "    error_level = ImageChops.difference(Image.fromarray(original_np), Image.fromarray(resized_np))\n",
    "\n",
    "    # Enhance the error level image\n",
    "    enhancer = ImageEnhance.Contrast(error_level)\n",
    "    error_level = enhancer.enhance(2)\n",
    "\n",
    "    # Save ELA image\n",
    "    error_level.save(output_path)\n",
    "\n",
    "def process_videos(video_files, output_folder):\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for video_file in video_files:\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video file {video_file}\")\n",
    "            continue\n",
    "\n",
    "        frame_number = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Resize frame\n",
    "            resized_frame = resize_frame(frame)\n",
    "\n",
    "            # Save resized frame\n",
    "            frame_filename = f\"{output_folder}/frame_{frame_number}.png\"\n",
    "            cv2.imwrite(frame_filename, resized_frame)\n",
    "\n",
    "            # Apply ELA\n",
    "            ela_output = f\"{output_folder}/ela_frame_{frame_number}.png\"\n",
    "            apply_ela(frame_filename, ela_output)\n",
    "\n",
    "            frame_number += 1\n",
    "\n",
    "        cap.release()\n",
    "        print(f\"Processing complete for {video_file}\")\n",
    "\n",
    "# Example usage\n",
    "video_files = [\"test_videos/Deepfake Scam Example Featuring Martin Lewis.mp4\", \"test_videos/Deepfake Example Presented by Senator Richard Blumenthal.mp4\", \"test_videos/Supporting Local Retailers This Diwali ｜ Not Just A Cadbury Ad Campaign Video.mp4\"]\n",
    "output_folder = \"output_frames\"\n",
    "\n",
    "process_videos(video_files, output_folder)\n"
   ],
   "id": "6b1672b7af9ffb8a",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'PIL.Image' has no attribute 'ANTIALIAS'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[47], line 77\u001B[0m\n\u001B[1;32m     74\u001B[0m video_files \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_videos/Deepfake Scam Example Featuring Martin Lewis.mp4\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_videos/Deepfake Example Presented by Senator Richard Blumenthal.mp4\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_videos/Supporting Local Retailers This Diwali ｜ Not Just A Cadbury Ad Campaign Video.mp4\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     75\u001B[0m output_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_frames\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 77\u001B[0m \u001B[43mprocess_videos\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvideo_files\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_folder\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[47], line 66\u001B[0m, in \u001B[0;36mprocess_videos\u001B[0;34m(video_files, output_folder)\u001B[0m\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;66;03m# Apply ELA\u001B[39;00m\n\u001B[1;32m     65\u001B[0m     ela_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutput_folder\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/ela_frame_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mframe_number\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.png\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 66\u001B[0m     \u001B[43mapply_ela\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe_filename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mela_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     68\u001B[0m     frame_number \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     70\u001B[0m cap\u001B[38;5;241m.\u001B[39mrelease()\n",
      "Cell \u001B[0;32mIn[47], line 17\u001B[0m, in \u001B[0;36mapply_ela\u001B[0;34m(image_path, output_path, scale_factor)\u001B[0m\n\u001B[1;32m     14\u001B[0m original \u001B[38;5;241m=\u001B[39m original\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Resize image\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m resized \u001B[38;5;241m=\u001B[39m original\u001B[38;5;241m.\u001B[39mresize((\u001B[38;5;28mint\u001B[39m(original\u001B[38;5;241m.\u001B[39mwidth \u001B[38;5;241m*\u001B[39m scale_factor), \u001B[38;5;28mint\u001B[39m(original\u001B[38;5;241m.\u001B[39mheight \u001B[38;5;241m*\u001B[39m scale_factor)), \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mANTIALIAS\u001B[49m)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Save resized image\u001B[39;00m\n\u001B[1;32m     20\u001B[0m resized\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresized_image.png\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'PIL.Image' has no attribute 'ANTIALIAS'"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T20:20:02.085684Z",
     "start_time": "2024-09-01T20:19:06.108351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "\n",
    "def resize_frame(frame, scale_factor=0.5):\n",
    "    height, width = frame.shape[:2]\n",
    "    new_size = (int(width * scale_factor), int(height * scale_factor))\n",
    "    resized_frame = cv2.resize(frame, new_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "    return resized_frame\n",
    "\n",
    "def apply_ela(image_path, output_path, scale_factor=0.5):\n",
    "    original = Image.open(image_path)\n",
    "    original = original.convert(\"RGB\")\n",
    "\n",
    "    # Resize image\n",
    "    resized = original.resize((int(original.width * scale_factor), int(original.height * scale_factor)), Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Save resized image\n",
    "    resized.save(\"resized_image.png\")\n",
    "\n",
    "    # Reopen resized image\n",
    "    resized = Image.open(\"resized_image.png\")\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    original_np = np.array(original)\n",
    "    resized_np = np.array(resized)\n",
    "\n",
    "    # Calculate error level\n",
    "    error_level = ImageChops.difference(Image.fromarray(original_np), Image.fromarray(resized_np))\n",
    "\n",
    "    # Enhance the error level image\n",
    "    enhancer = ImageEnhance.Contrast(error_level)\n",
    "    error_level = enhancer.enhance(2)\n",
    "\n",
    "    # Save ELA image\n",
    "    error_level.save(output_path)\n",
    "\n",
    "def process_videos(video_files, output_folder):\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for video_file in video_files:\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video file {video_file}\")\n",
    "            continue\n",
    "\n",
    "        frame_number = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Resize frame\n",
    "            resized_frame = resize_frame(frame)\n",
    "\n",
    "            # Save resized frame\n",
    "            frame_filename = f\"{output_folder}/frame_{frame_number}.png\"\n",
    "            cv2.imwrite(frame_filename, resized_frame)\n",
    "\n",
    "            # Apply ELA\n",
    "            ela_output = f\"{output_folder}/ela_frame_{frame_number}.png\"\n",
    "            apply_ela(frame_filename, ela_output)\n",
    "\n",
    "            frame_number += 1\n",
    "\n",
    "        cap.release()\n",
    "        print(f\"Processing complete for {video_file}\")\n",
    "\n",
    "# Example usage\n",
    "video_files = [\"test_videos/Deepfake Scam Example Featuring Martin Lewis.mp4\", \"test_videos/Deepfake Example Presented by Senator Richard Blumenthal.mp4\", \"test_videos/Supporting Local Retailers This Diwali ｜ Not Just A Cadbury Ad Campaign Video.mp4\"]\n",
    "output_folder = \"output_frames\"\n",
    "\n",
    "process_videos(video_files, output_folder)\n"
   ],
   "id": "d9909bfd4bfebafc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete for test_videos/Deepfake Scam Example Featuring Martin Lewis.mp4\n",
      "Processing complete for test_videos/Deepfake Example Presented by Senator Richard Blumenthal.mp4\n",
      "Processing complete for test_videos/Supporting Local Retailers This Diwali ｜ Not Just A Cadbury Ad Campaign Video.mp4\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T20:23:54.344720Z",
     "start_time": "2024-09-01T20:22:57.763609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for different folder per video\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "\n",
    "def resize_frame(frame, scale_factor=0.5):\n",
    "    height, width = frame.shape[:2]\n",
    "    new_size = (int(width * scale_factor), int(height * scale_factor))\n",
    "    resized_frame = cv2.resize(frame, new_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "    return resized_frame\n",
    "\n",
    "def apply_ela(image_path, output_path, scale_factor=0.5):\n",
    "    original = Image.open(image_path)\n",
    "    original = original.convert(\"RGB\")\n",
    "\n",
    "    # Resize image\n",
    "    resized = original.resize((int(original.width * scale_factor), int(original.height * scale_factor)), Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Save resized image\n",
    "    resized.save(\"resized_image.png\")\n",
    "\n",
    "    # Reopen resized image\n",
    "    resized = Image.open(\"resized_image.png\")\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    original_np = np.array(original)\n",
    "    resized_np = np.array(resized)\n",
    "\n",
    "    # Calculate error level\n",
    "    error_level = ImageChops.difference(Image.fromarray(original_np), Image.fromarray(resized_np))\n",
    "\n",
    "    # Enhance the error level image\n",
    "    enhancer = ImageEnhance.Contrast(error_level)\n",
    "    error_level = enhancer.enhance(2)\n",
    "\n",
    "    # Save ELA image\n",
    "    error_level.save(output_path)\n",
    "\n",
    "def process_videos(video_files, output_folder):\n",
    "    # Create the output base directory if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for video_file in video_files:\n",
    "        # Create a subfolder for each video\n",
    "        video_name = os.path.splitext(os.path.basename(video_file))[0]\n",
    "        video_output_folder = os.path.join(output_folder, video_name)\n",
    "        if not os.path.exists(video_output_folder):\n",
    "            os.makedirs(video_output_folder)\n",
    "\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video file {video_file}\")\n",
    "            continue\n",
    "\n",
    "        frame_number = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Resize frame\n",
    "            resized_frame = resize_frame(frame)\n",
    "\n",
    "            # Save resized frame\n",
    "            frame_filename = os.path.join(video_output_folder, f\"frame_{frame_number}.png\")\n",
    "            cv2.imwrite(frame_filename, resized_frame)\n",
    "\n",
    "            # Apply ELA\n",
    "            ela_output = os.path.join(video_output_folder, f\"ela_frame_{frame_number}.png\")\n",
    "            apply_ela(frame_filename, ela_output)\n",
    "\n",
    "            frame_number += 1\n",
    "\n",
    "        cap.release()\n",
    "        print(f\"Processing complete for {video_file}\")\n",
    "\n",
    "# Example usage\n",
    "video_files = [\"test_videos/Deepfake Scam Example Featuring Martin Lewis.mp4\", \"test_videos/Deepfake Example Presented by Senator Richard Blumenthal.mp4\", \"test_videos/Supporting Local Retailers This Diwali ｜ Not Just A Cadbury Ad Campaign Video.mp4\"]\n",
    "output_folder = \"output_frames\"\n",
    "\n",
    "process_videos(video_files, output_folder)\n"
   ],
   "id": "3c09c8da84b22bea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete for test_videos/Deepfake Scam Example Featuring Martin Lewis.mp4\n",
      "Processing complete for test_videos/Deepfake Example Presented by Senator Richard Blumenthal.mp4\n",
      "Processing complete for test_videos/Supporting Local Retailers This Diwali ｜ Not Just A Cadbury Ad Campaign Video.mp4\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T20:25:52.900435Z",
     "start_time": "2024-09-01T20:25:23.517196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def resize_frame(frame, scale_factor=0.5):\n",
    "    height, width = frame.shape[:2]\n",
    "    new_size = (int(width * scale_factor), int(height * scale_factor))\n",
    "    resized_frame = cv2.resize(frame, new_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "    return resized_frame\n",
    "\n",
    "def apply_ela(image_path, scale_factor=0.5):\n",
    "    original = Image.open(image_path)\n",
    "    original = original.convert(\"RGB\")\n",
    "\n",
    "    # Resize image\n",
    "    resized = original.resize((int(original.width * scale_factor), int(original.height * scale_factor)), Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    original_np = np.array(original)\n",
    "    resized_np = np.array(resized)\n",
    "\n",
    "    # Calculate error level\n",
    "    error_level = ImageChops.difference(Image.fromarray(original_np), Image.fromarray(resized_np))\n",
    "\n",
    "    # Convert error level image to numpy array\n",
    "    error_level_np = np.array(error_level)\n",
    "\n",
    "    # Calculate the mean error level value\n",
    "    mean_error = np.mean(error_level_np)\n",
    "\n",
    "    return mean_error\n",
    "\n",
    "def process_videos(video_files, output_folder):\n",
    "    # Create the output base directory if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for video_file in video_files:\n",
    "        # Create a subfolder for each video\n",
    "        video_name = os.path.splitext(os.path.basename(video_file))[0]\n",
    "        video_output_folder = os.path.join(output_folder, video_name)\n",
    "        if not os.path.exists(video_output_folder):\n",
    "            os.makedirs(video_output_folder)\n",
    "\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video file {video_file}\")\n",
    "            continue\n",
    "\n",
    "        frame_number = 0\n",
    "        mean_errors = []\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Resize frame\n",
    "            resized_frame = resize_frame(frame)\n",
    "\n",
    "            # Save resized frame\n",
    "            frame_filename = os.path.join(video_output_folder, f\"frame_{frame_number}.png\")\n",
    "            cv2.imwrite(frame_filename, resized_frame)\n",
    "\n",
    "            # Calculate ELA and get mean error level\n",
    "            mean_error = apply_ela(frame_filename)\n",
    "            mean_errors.append(mean_error)\n",
    "\n",
    "            frame_number += 1\n",
    "\n",
    "        cap.release()\n",
    "        print(f\"Processing complete for {video_file}\")\n",
    "\n",
    "        # Plotting the mean error levels\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(mean_errors, label=f'Error Level - {video_name}')\n",
    "        plt.xlabel('Frame Number')\n",
    "        plt.ylabel('Mean Error Level')\n",
    "        plt.title(f'Mean Error Level Across Frames for {video_name}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_folder, video_name, 'error_level_plot.png'))\n",
    "        plt.close()\n",
    "\n",
    "# Example usage\n",
    "video_files = [\"test_videos/Deepfake Scam Example Featuring Martin Lewis.mp4\", \"test_videos/Deepfake Example Presented by Senator Richard Blumenthal.mp4\", \"test_videos/Supporting Local Retailers This Diwali ｜ Not Just A Cadbury Ad Campaign Video.mp4\"]\n",
    "output_folder = \"output_frames\"\n",
    "\n",
    "process_videos(video_files, output_folder)\n"
   ],
   "id": "e1596216794f90d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete for test_videos/Deepfake Scam Example Featuring Martin Lewis.mp4\n",
      "Processing complete for test_videos/Deepfake Example Presented by Senator Richard Blumenthal.mp4\n",
      "Processing complete for test_videos/Supporting Local Retailers This Diwali ｜ Not Just A Cadbury Ad Campaign Video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jd/5vc1z8913t55htnkf031mprw0000gn/T/ipykernel_5519/1730319259.py:85: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from current font.\n",
      "  plt.savefig(os.path.join(output_folder, video_name, 'error_level_plot.png'))\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f\"Processing complete for {video_files}\")",
   "id": "3460933b62fcdf6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T20:28:54.428530Z",
     "start_time": "2024-09-01T20:28:54.419598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def summarize_error_levels(video_files, output_folder):\n",
    "    for video_file in video_files:\n",
    "        video_name = os.path.splitext(os.path.basename(video_file))[0]\n",
    "        video_output_folder = os.path.join(output_folder, video_name)\n",
    "\n",
    "        if not os.path.exists(video_output_folder):\n",
    "            print(f\"Output folder for {video_name} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        frame_files = [f for f in os.listdir(video_output_folder) if f.endswith('.png') and 'ela' in f]\n",
    "\n",
    "        max_differences = []\n",
    "\n",
    "        for frame_file in frame_files:\n",
    "            ela_file = os.path.join(video_output_folder, frame_file)\n",
    "            error_img = Image.open(ela_file)\n",
    "            error_np = np.array(error_img)\n",
    "            max_difference = np.max(error_np)\n",
    "            max_differences.append(max_difference)\n",
    "\n",
    "        if not max_differences:\n",
    "            print(f\"No ELA frames found for {video_name}.\")\n",
    "            continue\n",
    "\n",
    "        max_differences = np.array(max_differences)\n",
    "        summary = {\n",
    "            'Video': video_name,\n",
    "            'Number of Frames': len(max_differences),\n",
    "            'Maximum Error Level': np.max(max_differences),\n",
    "            'Minimum Error Level': np.min(max_differences),\n",
    "            'Average Error Level': np.mean(max_differences),\n",
    "            'Standard Deviation': np.std(max_differences)\n",
    "        }\n",
    "\n",
    "        print(f\"Summary for {video_name}:\")\n",
    "        print(f\"  Number of Frames: {summary['Number of Frames']}\")\n",
    "        print(f\"  Maximum Error Level: {summary['Maximum Error Level']}\")\n",
    "        print(f\"  Minimum Error Level: {summary['Minimum Error Level']}\")\n",
    "        print(f\"  Average Error Level: {summary['Average Error Level']:.2f}\")\n",
    "        print(f\"  Standard Deviation: {summary['Standard Deviation']:.2f}\")\n",
    "        print()\n",
    "\n",
    "# Example usage\n",
    "summarize_error_levels(video_files, output_folder)\n"
   ],
   "id": "28dd7403bf04553f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ELA frames found for Deepfake Scam Example Featuring Martin Lewis.\n",
      "No ELA frames found for Deepfake Example Presented by Senator Richard Blumenthal.\n",
      "No ELA frames found for Supporting Local Retailers This Diwali ｜ Not Just A Cadbury Ad Campaign Video.\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T20:29:52.439746Z",
     "start_time": "2024-09-01T20:29:52.435377Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a7fe93dc5338cad1",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T20:14:45.921674Z",
     "start_time": "2024-09-01T20:14:41.767774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import cv2\n",
    "# from PIL import Image, ImageChops, ImageEnhance\n",
    "# import os\n",
    "# \n",
    "# # Function to resize the image according to CNN's input layer\n",
    "# def resize_image(image, target_size=(224, 224)):\n",
    "#     return image.resize(target_size, Image.LANCZOS)\n",
    "# \n",
    "# # Function to perform ELA\n",
    "# def perform_ela(original_image, scale=10):\n",
    "#     # Save the image in a lossless format\n",
    "#     temp_filename = \"temp_ela.png\"\n",
    "#     original_image.save(temp_filename, \"PNG\")\n",
    "# \n",
    "#     # Reload the saved image\n",
    "#     compressed_image = Image.open(temp_filename)\n",
    "# \n",
    "#     # Find the difference between the original and compressed images\n",
    "#     ela_image = ImageChops.difference(original_image, compressed_image)\n",
    "# \n",
    "#     # Debugging: Save the difference image\n",
    "#     ela_debug_filename = \"ela_debug.png\"\n",
    "#     ela_image.save(ela_debug_filename)\n",
    "# \n",
    "#     # Debugging information\n",
    "#     extrema = ela_image.getextrema()\n",
    "#     max_diff = max([ex[1] for ex in extrema])\n",
    "#     print(f\"Max difference: {max_diff}\")\n",
    "# \n",
    "#     if max_diff == 0:\n",
    "#         print(\"No difference detected.\")\n",
    "#         return None\n",
    "# \n",
    "#     # Adjust scale for better visualization\n",
    "#     scale = scale / max_diff\n",
    "#     print(f\"Scaling factor: {scale}\")\n",
    "# \n",
    "#     # Enhance contrast and scale the image\n",
    "#     ela_image = ImageEnhance.Contrast(ela_image).enhance(scale)\n",
    "# \n",
    "#     # Convert to grayscale for better visualization\n",
    "#     ela_image = ela_image.convert(\"L\")\n",
    "# \n",
    "#     return ela_image\n",
    "# \n",
    "# # Function to process videos from the dataset\n",
    "# def process_video(video_path, output_dir, frame_skip=30):\n",
    "#     video_capture = cv2.VideoCapture(video_path)\n",
    "#     frame_count = 0\n",
    "#     saved_frame_count = 0\n",
    "# \n",
    "#     while True:\n",
    "#         ret, frame = video_capture.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "# \n",
    "#         # Skip frames to reduce processing load\n",
    "#         if frame_count % frame_skip == 0:\n",
    "#             # Convert frame to PIL image\n",
    "#             pil_frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "# \n",
    "#             # Resize the image\n",
    "#             resized_image = resize_image(pil_frame)\n",
    "# \n",
    "#             # Perform ELA\n",
    "#             ela_image = perform_ela(resized_image)\n",
    "# \n",
    "#             if ela_image is not None:\n",
    "#                 # Save the ELA image\n",
    "#                 ela_filename = os.path.join(output_dir, f\"ela_frame_{saved_frame_count:04d}.png\")\n",
    "#                 ela_image.save(ela_filename)\n",
    "#                 saved_frame_count += 1\n",
    "# \n",
    "#         frame_count += 1\n",
    "# \n",
    "#     video_capture.release()\n",
    "# \n",
    "# # Function to process all videos in a directory\n",
    "# def process_dataset_videos(dataset_dir, output_base_dir, frame_skip=30):\n",
    "#     for root, dirs, files in os.walk(dataset_dir):\n",
    "#         for file in files:\n",
    "#             if file.endswith('.mp4'):\n",
    "#                 video_path = os.path.join(root, file)\n",
    "# \n",
    "#                 # Create an output directory for the video\n",
    "#                 output_dir = os.path.join(output_base_dir, os.path.splitext(file)[0])\n",
    "#                 os.makedirs(output_dir, exist_ok=True)\n",
    "# \n",
    "#                 # Process the video\n",
    "#                 print(f\"Processing video: {video_path}\")\n",
    "#                 process_video(video_path, output_dir, frame_skip)\n",
    "# \n",
    "# # Replace with the path to your downloaded videos\n",
    "# dataset_dir = \"test_videos\"\n",
    "# # Replace with the directory where you want to save ELA frames\n",
    "# output_base_dir = \"ela_results\"\n",
    "# \n",
    "# # Process all videos in the dataset\n",
    "# process_dataset_videos(dataset_dir, output_base_dir, frame_skip=30)\n"
   ],
   "id": "f51ee50a831c08eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: test_videos/Deepfake Scam Example Featuring Martin Lewis.mp4\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Processing video: test_videos/Deepfake Example Presented by Senator Richard Blumenthal.mp4\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Processing video: test_videos/Supporting Local Retailers This Diwali ｜ Not Just A Cadbury Ad Campaign Video.mp4\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n",
      "Max difference: 0\n",
      "No difference detected.\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "1f6dfb10235ffdbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T20:03:25.329639Z",
     "start_time": "2024-09-01T20:03:21.968627Z"
    }
   },
   "source": [
    "# import cv2\n",
    "# from PIL import Image, ImageChops, ImageEnhance\n",
    "# import os\n",
    "# \n",
    "# # Function to resize the image according to CNN's input layer\n",
    "# def resize_image(image, target_size=(224, 224)):\n",
    "#     return image.resize(target_size, Image.LANCZOS)\n",
    "# \n",
    "# # Function to save and reload the image to perform ELA\n",
    "# def perform_ela(image, scale=10):\n",
    "#     # Save the image at a lower quality\n",
    "#     temp_filename = \"temp_ela.jpg\"\n",
    "#     image.save(temp_filename, \"JPEG\", quality=90)\n",
    "# \n",
    "#     # Reload the saved image\n",
    "#     compressed_image = Image.open(temp_filename)\n",
    "# \n",
    "#     # Find the difference between the original and compressed images\n",
    "#     ela_image = ImageChops.difference(image, compressed_image)\n",
    "# \n",
    "#     # Enhance the differences for visualization\n",
    "#     extrema = ela_image.getextrema()\n",
    "#     max_diff = max([ex[1] for ex in extrema])\n",
    "#     scale = scale / max_diff if max_diff > 0 else 1\n",
    "# \n",
    "#     ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "# \n",
    "#     return ela_image\n",
    "# \n",
    "# # Function to process videos from the dataset\n",
    "# def process_video(video_path, output_dir, frame_skip=30):\n",
    "#     video_capture = cv2.VideoCapture(video_path)\n",
    "#     frame_count = 0\n",
    "#     saved_frame_count = 0\n",
    "# \n",
    "#     while True:\n",
    "#         ret, frame = video_capture.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "# \n",
    "#         # Skip frames to reduce processing load\n",
    "#         if frame_count % frame_skip == 0:\n",
    "#             # Convert frame to PIL image\n",
    "#             pil_frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "# \n",
    "#             # Resize the image\n",
    "#             resized_image = resize_image(pil_frame)\n",
    "# \n",
    "#             # Perform ELA\n",
    "#             ela_image = perform_ela(resized_image)\n",
    "# \n",
    "#             # Save the ELA image\n",
    "#             ela_filename = os.path.join(output_dir, f\"ela_frame_{saved_frame_count:04d}.png\")\n",
    "#             ela_image.save(ela_filename)\n",
    "# \n",
    "#             saved_frame_count += 1\n",
    "# \n",
    "#         frame_count += 1\n",
    "# \n",
    "#     video_capture.release()\n",
    "# \n",
    "# # Function to process all videos in a directory\n",
    "# def process_dataset_videos(dataset_dir, output_base_dir, frame_skip=30):\n",
    "#     for root, dirs, files in os.walk(dataset_dir):\n",
    "#         for file in files:\n",
    "#             if file.endswith('.mp4'):\n",
    "#                 video_path = os.path.join(root, file)\n",
    "# \n",
    "#                 # Create an output directory for the video\n",
    "#                 output_dir = os.path.join(output_base_dir, os.path.splitext(file)[0])\n",
    "#                 os.makedirs(output_dir, exist_ok=True)\n",
    "# \n",
    "#                 # Process the video\n",
    "#                 print(f\"Processing video: {video_path}\")\n",
    "#                 process_video(video_path, output_dir, frame_skip)\n",
    "# \n",
    "# # Replace with the path to your downloaded videos\n",
    "# dataset_dir = \"test_videos\"\n",
    "# # Replace with the directory where you want to save ELA frames\n",
    "# output_base_dir = \"ela_results\"\n",
    "# \n",
    "# # Process all videos in the dataset\n",
    "# process_dataset_videos(dataset_dir, output_base_dir, frame_skip=30)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: test_videos/Deepfake Scam Example Featuring Martin Lewis.mp4\n",
      "Processing video: test_videos/Deepfake Example Presented by Senator Richard Blumenthal.mp4\n",
      "Processing video: test_videos/Supporting Local Retailers This Diwali ｜ Not Just A Cadbury Ad Campaign Video.mp4\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T20:07:55.873730Z",
     "start_time": "2024-09-01T20:07:52.781549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import cv2\n",
    "# from PIL import Image, ImageChops, ImageEnhance\n",
    "# import os\n",
    "# \n",
    "# # Function to resize the image according to CNN's input layer\n",
    "# def resize_image(image, target_size=(224, 224)):\n",
    "#     return image.resize(target_size, Image.LANCZOS)\n",
    "# \n",
    "# # Function to save and reload the image to perform ELA\n",
    "# def perform_ela(image, scale=10):\n",
    "#     # Save the image at a lower quality\n",
    "#     temp_filename = \"temp_ela.jpg\"\n",
    "#     image.save(temp_filename, \"JPEG\", quality=90)\n",
    "# \n",
    "#     # Reload the saved image\n",
    "#     compressed_image = Image.open(temp_filename)\n",
    "# \n",
    "#     # Find the difference between the original and compressed images\n",
    "#     ela_image = ImageChops.difference(image, compressed_image)\n",
    "# \n",
    "#     # Enhance the differences for visualization\n",
    "#     extrema = ela_image.getextrema()\n",
    "#     max_diff = max([ex[1] for ex in extrema])\n",
    "#     scale = scale / max_diff if max_diff > 0 else 1\n",
    "# \n",
    "#     # Increase contrast to make differences more visible\n",
    "#     ela_image = ImageEnhance.Contrast(ela_image).enhance(scale)\n",
    "#     # Convert to grayscale for better visualization\n",
    "#     ela_image = ela_image.convert(\"L\")\n",
    "# \n",
    "#     return ela_image\n",
    "# \n",
    "# # Function to process videos from the dataset\n",
    "# def process_video(video_path, output_dir, frame_skip=30):\n",
    "#     video_capture = cv2.VideoCapture(video_path)\n",
    "#     frame_count = 0\n",
    "#     saved_frame_count = 0\n",
    "# \n",
    "#     while True:\n",
    "#         ret, frame = video_capture.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "# \n",
    "#         # Skip frames to reduce processing load\n",
    "#         if frame_count % frame_skip == 0:\n",
    "#             # Convert frame to PIL image\n",
    "#             pil_frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "# \n",
    "#             # Resize the image\n",
    "#             resized_image = resize_image(pil_frame)\n",
    "# \n",
    "#             # Perform ELA\n",
    "#             ela_image = perform_ela(resized_image)\n",
    "# \n",
    "#             # Save the ELA image\n",
    "#             ela_filename = os.path.join(output_dir, f\"ela_frame_{saved_frame_count:04d}.png\")\n",
    "#             ela_image.save(ela_filename)\n",
    "# \n",
    "#             saved_frame_count += 1\n",
    "# \n",
    "#         frame_count += 1\n",
    "# \n",
    "#     video_capture.release()\n",
    "# \n",
    "# # Function to process all videos in a directory\n",
    "# def process_dataset_videos(dataset_dir, output_base_dir, frame_skip=30):\n",
    "#     for root, dirs, files in os.walk(dataset_dir):\n",
    "#         for file in files:\n",
    "#             if file.endswith('.mp4'):\n",
    "#                 video_path = os.path.join(root, file)\n",
    "# \n",
    "#                 # Create an output directory for the video\n",
    "#                 output_dir = os.path.join(output_base_dir, os.path.splitext(file)[0])\n",
    "#                 os.makedirs(output_dir, exist_ok=True)\n",
    "# \n",
    "#                 # Process the video\n",
    "#                 print(f\"Processing video: {video_path}\")\n",
    "#                 process_video(video_path, output_dir, frame_skip)\n",
    "# \n",
    "# # Replace with the path to your downloaded videos\n",
    "# dataset_dir = \"test_videos\"\n",
    "# # Replace with the directory where you want to save ELA frames\n",
    "# output_base_dir = \"ela_results\"\n",
    "# \n",
    "# # Process all videos in the dataset\n",
    "# process_dataset_videos(dataset_dir, output_base_dir, frame_skip=30)\n"
   ],
   "id": "680718769a5e63d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: test_videos/Deepfake Scam Example Featuring Martin Lewis.mp4\n",
      "Processing video: test_videos/Deepfake Example Presented by Senator Richard Blumenthal.mp4\n",
      "Processing video: test_videos/Supporting Local Retailers This Diwali ｜ Not Just A Cadbury Ad Campaign Video.mp4\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T20:10:01.788652Z",
     "start_time": "2024-09-01T20:09:57.736374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import cv2\n",
    "# from PIL import Image, ImageChops, ImageEnhance\n",
    "# import os\n",
    "# \n",
    "# # Function to resize the image according to CNN's input layer\n",
    "# def resize_image(image, target_size=(224, 224)):\n",
    "#     return image.resize(target_size, Image.LANCZOS)\n",
    "# \n",
    "# # Function to save and reload the image to perform ELA\n",
    "# def perform_ela(image, scale=10):\n",
    "#     # Save the image in a lossless format to avoid compression artifacts\n",
    "#     temp_filename = \"temp_ela.png\"\n",
    "#     image.save(temp_filename, \"PNG\")\n",
    "# \n",
    "#     # Reload the saved image\n",
    "#     compressed_image = Image.open(temp_filename)\n",
    "# \n",
    "#     # Find the difference between the original and compressed images\n",
    "#     ela_image = ImageChops.difference(image, compressed_image)\n",
    "# \n",
    "#     # Debugging information\n",
    "#     extrema = ela_image.getextrema()\n",
    "#     max_diff = max([ex[1] for ex in extrema])\n",
    "#     print(f\"Max difference: {max_diff}\")\n",
    "# \n",
    "#     # Adjust scale for better visualization\n",
    "#     scale = scale / max_diff if max_diff > 0 else 1\n",
    "#     print(f\"Scaling factor: {scale}\")\n",
    "# \n",
    "#     # Enhance contrast and scale the image\n",
    "#     ela_image = ImageEnhance.Contrast(ela_image).enhance(scale)\n",
    "# \n",
    "#     # Convert to grayscale for better visualization\n",
    "#     ela_image = ela_image.convert(\"L\")\n",
    "# \n",
    "#     return ela_image\n",
    "# \n",
    "# # Function to process videos from the dataset\n",
    "# def process_video(video_path, output_dir, frame_skip=30):\n",
    "#     video_capture = cv2.VideoCapture(video_path)\n",
    "#     frame_count = 0\n",
    "#     saved_frame_count = 0\n",
    "# \n",
    "#     while True:\n",
    "#         ret, frame = video_capture.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "# \n",
    "#         # Skip frames to reduce processing load\n",
    "#         if frame_count % frame_skip == 0:\n",
    "#             # Convert frame to PIL image\n",
    "#             pil_frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "# \n",
    "#             # Resize the image\n",
    "#             resized_image = resize_image(pil_frame)\n",
    "# \n",
    "#             # Perform ELA\n",
    "#             ela_image = perform_ela(resized_image)\n",
    "# \n",
    "#             # Save the ELA image\n",
    "#             ela_filename = os.path.join(output_dir, f\"ela_frame_{saved_frame_count:04d}.png\")\n",
    "#             ela_image.save(ela_filename)\n",
    "# \n",
    "#             saved_frame_count += 1\n",
    "# \n",
    "#         frame_count += 1\n",
    "# \n",
    "#     video_capture.release()\n",
    "# \n",
    "# # Function to process all videos in a directory\n",
    "# def process_dataset_videos(dataset_dir, output_base_dir, frame_skip=30):\n",
    "#     for root, dirs, files in os.walk(dataset_dir):\n",
    "#         for file in files:\n",
    "#             if file.endswith('.mp4'):\n",
    "#                 video_path = os.path.join(root, file)\n",
    "# \n",
    "#                 # Create an output directory for the video\n",
    "#                 output_dir = os.path.join(output_base_dir, os.path.splitext(file)[0])\n",
    "#                 os.makedirs(output_dir, exist_ok=True)\n",
    "# \n",
    "#                 # Process the video\n",
    "#                 print(f\"Processing video: {video_path}\")\n",
    "#                 process_video(video_path, output_dir, frame_skip)\n",
    "# \n",
    "# # Replace with the path to your downloaded videos\n",
    "# dataset_dir = \"test_videos\"\n",
    "# # Replace with the directory where you want to save ELA frames\n",
    "# output_base_dir = \"ela_results\"\n",
    "# \n",
    "# # Process all videos in the dataset\n",
    "# process_dataset_videos(dataset_dir, output_base_dir, frame_skip=30)\n"
   ],
   "id": "2e022f2ea260f579",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: test_videos/Deepfake Scam Example Featuring Martin Lewis.mp4\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Processing video: test_videos/Deepfake Example Presented by Senator Richard Blumenthal.mp4\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Processing video: test_videos/Supporting Local Retailers This Diwali ｜ Not Just A Cadbury Ad Campaign Video.mp4\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T20:11:46.272151Z",
     "start_time": "2024-09-01T20:11:42.049501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import cv2\n",
    "# from PIL import Image, ImageChops, ImageEnhance\n",
    "# import os\n",
    "# \n",
    "# # Function to resize the image according to CNN's input layer\n",
    "# def resize_image(image, target_size=(224, 224)):\n",
    "#     return image.resize(target_size, Image.LANCZOS)\n",
    "# \n",
    "# # Function to save and reload the image to perform ELA\n",
    "# def perform_ela(image, scale=10):\n",
    "#     # Save the image in a lossless format to avoid compression artifacts\n",
    "#     temp_filename = \"temp_ela.png\"\n",
    "#     image.save(temp_filename, \"PNG\")\n",
    "# \n",
    "#     # Reload the saved image\n",
    "#     compressed_image = Image.open(temp_filename)\n",
    "# \n",
    "#     # Find the difference between the original and compressed images\n",
    "#     ela_image = ImageChops.difference(image, compressed_image)\n",
    "# \n",
    "#     # Debugging: Save the difference image\n",
    "#     ela_debug_filename = \"ela_debug.png\"\n",
    "#     ela_image.save(ela_debug_filename)\n",
    "# \n",
    "#     # Debugging information\n",
    "#     extrema = ela_image.getextrema()\n",
    "#     max_diff = max([ex[1] for ex in extrema])\n",
    "#     print(f\"Max difference: {max_diff}\")\n",
    "# \n",
    "#     # Adjust scale for better visualization\n",
    "#     scale = scale / max_diff if max_diff > 0 else 1\n",
    "#     print(f\"Scaling factor: {scale}\")\n",
    "# \n",
    "#     # Enhance contrast and scale the image\n",
    "#     ela_image = ImageEnhance.Contrast(ela_image).enhance(scale)\n",
    "# \n",
    "#     # Convert to grayscale for better visualization\n",
    "#     ela_image = ela_image.convert(\"L\")\n",
    "# \n",
    "#     return ela_image\n",
    "# \n",
    "# # Function to process videos from the dataset\n",
    "# def process_video(video_path, output_dir, frame_skip=30):\n",
    "#     video_capture = cv2.VideoCapture(video_path)\n",
    "#     frame_count = 0\n",
    "#     saved_frame_count = 0\n",
    "# \n",
    "#     while True:\n",
    "#         ret, frame = video_capture.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "# \n",
    "#         # Skip frames to reduce processing load\n",
    "#         if frame_count % frame_skip == 0:\n",
    "#             # Convert frame to PIL image\n",
    "#             pil_frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "# \n",
    "#             # Resize the image\n",
    "#             resized_image = resize_image(pil_frame)\n",
    "# \n",
    "#             # Perform ELA\n",
    "#             ela_image = perform_ela(resized_image)\n",
    "# \n",
    "#             # Save the ELA image\n",
    "#             ela_filename = os.path.join(output_dir, f\"ela_frame_{saved_frame_count:04d}.png\")\n",
    "#             ela_image.save(ela_filename)\n",
    "# \n",
    "#             saved_frame_count += 1\n",
    "# \n",
    "#         frame_count += 1\n",
    "# \n",
    "#     video_capture.release()\n",
    "# \n",
    "# # Function to process all videos in a directory\n",
    "# def process_dataset_videos(dataset_dir, output_base_dir, frame_skip=30):\n",
    "#     for root, dirs, files in os.walk(dataset_dir):\n",
    "#         for file in files:\n",
    "#             if file.endswith('.mp4'):\n",
    "#                 video_path = os.path.join(root, file)\n",
    "# \n",
    "#                 # Create an output directory for the video\n",
    "#                 output_dir = os.path.join(output_base_dir, os.path.splitext(file)[0])\n",
    "#                 os.makedirs(output_dir, exist_ok=True)\n",
    "# \n",
    "#                 # Process the video\n",
    "#                 print(f\"Processing video: {video_path}\")\n",
    "#                 process_video(video_path, output_dir, frame_skip)\n",
    "# \n",
    "# # Replace with the path to your downloaded videos\n",
    "# dataset_dir = \"test_videos\"\n",
    "# # Replace with the directory where you want to save ELA frames\n",
    "# output_base_dir = \"ela_results\"\n",
    "# \n",
    "# # Process all videos in the dataset\n",
    "# process_dataset_videos(dataset_dir, output_base_dir, frame_skip=30)\n"
   ],
   "id": "9d7b228992e0f9be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: test_videos/Deepfake Scam Example Featuring Martin Lewis.mp4\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Processing video: test_videos/Deepfake Example Presented by Senator Richard Blumenthal.mp4\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Processing video: test_videos/Supporting Local Retailers This Diwali ｜ Not Just A Cadbury Ad Campaign Video.mp4\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n",
      "Max difference: 0\n",
      "Scaling factor: 1\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e4cd84c43527e0f3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
